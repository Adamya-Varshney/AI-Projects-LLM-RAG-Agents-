{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"day-3-function-calling-with-the-gemini-api.ipynb","toc_visible":true},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"cellView":"form","id":"d6597b11df14","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T03:38:32.912199Z","iopub.execute_input":"2025-04-02T03:38:32.912633Z","iopub.status.idle":"2025-04-02T03:38:32.917592Z","shell.execute_reply.started":"2025-04-02T03:38:32.912595Z","shell.execute_reply":"2025-04-02T03:38:32.916461Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip uninstall -qqy jupyterlab  # Remove unused conflicting packages\n!pip install -U -q \"google-genai==1.7.0\"","metadata":{"id":"a24f42e469df","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T03:38:32.919797Z","iopub.execute_input":"2025-04-02T03:38:32.920216Z","iopub.status.idle":"2025-04-02T03:38:44.715773Z","shell.execute_reply.started":"2025-04-02T03:38:32.920171Z","shell.execute_reply":"2025-04-02T03:38:44.714399Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\n\ngenai.__version__","metadata":{"id":"02bb0f551e25","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T03:38:44.717541Z","iopub.execute_input":"2025-04-02T03:38:44.717976Z","iopub.status.idle":"2025-04-02T03:38:44.724899Z","shell.execute_reply.started":"2025-04-02T03:38:44.71793Z","shell.execute_reply":"2025-04-02T03:38:44.724164Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")","metadata":{"id":"5cc8325f051d","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T03:38:44.726062Z","iopub.execute_input":"2025-04-02T03:38:44.726389Z","iopub.status.idle":"2025-04-02T03:38:44.836913Z","shell.execute_reply.started":"2025-04-02T03:38:44.72636Z","shell.execute_reply":"2025-04-02T03:38:44.835873Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Automated retry","metadata":{}},{"cell_type":"code","source":"# Define a retry policy. The model might make multiple consecutive calls automatically\n# for a complex query, this ensures the client retries if it hits quota limits.\nfrom google.api_core import retry\n\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\nif not hasattr(genai.models.Models.generate_content, '__wrapped__'):\n  genai.models.Models.generate_content = retry.Retry(\n      predicate=is_retriable)(genai.models.Models.generate_content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T03:38:44.83927Z","iopub.execute_input":"2025-04-02T03:38:44.839579Z","iopub.status.idle":"2025-04-02T03:38:44.845406Z","shell.execute_reply.started":"2025-04-02T03:38:44.839549Z","shell.execute_reply":"2025-04-02T03:38:44.844512Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Create a local database\n\nFor this minimal example, you'll create a local SQLite database and add some synthetic data so you have something to query.\n\nLoad the `sql` IPython extension so you can interact with the database using magic commands (the `%` instructions) to create a new, empty SQLite database.","metadata":{"id":"ed8fc6062c62"}},{"cell_type":"code","source":"%load_ext sql\n%sql sqlite:///sample.db","metadata":{"id":"c98a627ef07b","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T03:38:44.846927Z","iopub.execute_input":"2025-04-02T03:38:44.847306Z","iopub.status.idle":"2025-04-02T03:38:44.861033Z","shell.execute_reply.started":"2025-04-02T03:38:44.847275Z","shell.execute_reply":"2025-04-02T03:38:44.860087Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Create the tables and insert some synthetic data. Feel free to tweak this structure and data.","metadata":{"id":"14e7bc18b8af"}},{"cell_type":"code","source":"%%sql\n-- Create the 'products' table\nCREATE TABLE IF NOT EXISTS products (\n  \tproduct_id INTEGER PRIMARY KEY AUTOINCREMENT,\n  \tproduct_name VARCHAR(255) NOT NULL,\n  \tprice DECIMAL(10, 2) NOT NULL\n  );\n\n-- Create the 'staff' table\nCREATE TABLE IF NOT EXISTS staff (\n  \tstaff_id INTEGER PRIMARY KEY AUTOINCREMENT,\n  \tfirst_name VARCHAR(255) NOT NULL,\n  \tlast_name VARCHAR(255) NOT NULL\n  );\n\n-- Create the 'orders' table\nCREATE TABLE IF NOT EXISTS orders (\n  \torder_id INTEGER PRIMARY KEY AUTOINCREMENT,\n  \tcustomer_name VARCHAR(255) NOT NULL,\n  \tstaff_id INTEGER NOT NULL,\n  \tproduct_id INTEGER NOT NULL,\n  \tFOREIGN KEY (staff_id) REFERENCES staff (staff_id),\n  \tFOREIGN KEY (product_id) REFERENCES products (product_id)\n  );\n\n-- Insert data into the 'products' table\nINSERT INTO products (product_name, price) VALUES\n  \t('Laptop', 799.99),\n  \t('Keyboard', 129.99),\n  \t('Mouse', 29.99);\n\n-- Insert data into the 'staff' table\nINSERT INTO staff (first_name, last_name) VALUES\n  \t('Alice', 'Smith'),\n  \t('Bob', 'Johnson'),\n  \t('Charlie', 'Williams');\n\n-- Insert data into the 'orders' table\nINSERT INTO orders (customer_name, staff_id, product_id) VALUES\n  \t('David Lee', 1, 1),\n  \t('Emily Chen', 2, 2),\n  \t('Frank Brown', 1, 3);","metadata":{"id":"4e186de46cf1","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T03:38:44.862411Z","iopub.execute_input":"2025-04-02T03:38:44.862813Z","iopub.status.idle":"2025-04-02T03:38:49.891423Z","shell.execute_reply.started":"2025-04-02T03:38:44.862768Z","shell.execute_reply":"2025-04-02T03:38:49.890326Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define database functions\n\nFunction calling with Gemini API's Python SDK can be implemented by defining [an OpenAPI schema](https://ai.google.dev/api/caching#Schema) that is passed to the model. You can also define Python functions and let the SDK inspect them to automatically define the schema. In this latter case, it's important that the functions are type annotated and have accurate docstrings that describe what the functions do - the model has no insight into the function body, so the docs function as the interface.\n\nBy providing three key pieces of functionality - listing tables, describing a table, and executing a query - the LLM (much like a human user) will have the basic tools needed to understand and interrogate the database.\n\nStart with a database connection that will be used across all of the functions.","metadata":{"id":"83901899a79b"}},{"cell_type":"code","source":"import sqlite3\n\ndb_file = \"sample.db\"\ndb_conn = sqlite3.connect(db_file)","metadata":{"id":"437168bc6b6e","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T03:38:49.893061Z","iopub.execute_input":"2025-04-02T03:38:49.893763Z","iopub.status.idle":"2025-04-02T03:38:49.89917Z","shell.execute_reply.started":"2025-04-02T03:38:49.893716Z","shell.execute_reply":"2025-04-02T03:38:49.898036Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The first function will list all tables available in the database. Define it, and test it out to ensure it works.","metadata":{"id":"b68b1a2c37d9"}},{"cell_type":"code","source":"def list_tables() -> list[str]:\n    \"\"\"Retrieve the names of all tables in the database.\"\"\"\n    # Include print logging statements so you can see when functions are being called.\n    print(' - DB CALL: list_tables()')\n\n    cursor = db_conn.cursor()\n\n    # Fetch the table names.\n    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n\n    tables = cursor.fetchall()\n    return [t[0] for t in tables]\n\n\nlist_tables()","metadata":{"id":"bdb0e4d2bb4b","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T03:38:49.900454Z","iopub.execute_input":"2025-04-02T03:38:49.90077Z","iopub.status.idle":"2025-04-02T03:38:49.922247Z","shell.execute_reply.started":"2025-04-02T03:38:49.900738Z","shell.execute_reply":"2025-04-02T03:38:49.921066Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Once the available tables is known, the next step a database user will need is to understand what columns are available in a given table. Define that too, and test that it works as expected.","metadata":{"id":"b6c010b1b6c2"}},{"cell_type":"code","source":"def describe_table(table_name: str) -> list[tuple[str, str]]:\n    \"\"\"Look up the table schema.\n\n    Returns:\n      List of columns, where each entry is a tuple of (column, type).\n    \"\"\"\n    print(f' - DB CALL: describe_table({table_name})')\n\n    cursor = db_conn.cursor()\n\n    cursor.execute(f\"PRAGMA table_info({table_name});\")\n\n    schema = cursor.fetchall()\n    # [column index, column name, column type, ...]\n    return [(col[1], col[2]) for col in schema]\n\n\ndescribe_table(\"products\")","metadata":{"id":"ecdb109298c4","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T03:38:49.923869Z","iopub.execute_input":"2025-04-02T03:38:49.924344Z","iopub.status.idle":"2025-04-02T03:38:49.935845Z","shell.execute_reply.started":"2025-04-02T03:38:49.924311Z","shell.execute_reply":"2025-04-02T03:38:49.934818Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now that the system knows what tables and columns are present, it has enough information to be able to generate and run a `SELECT` query. Now provide that functionality, and test that it works.","metadata":{"id":"f6053a2ca272"}},{"cell_type":"code","source":"def execute_query(sql: str) -> list[list[str]]:\n    \"\"\"Execute an SQL statement, returning the results.\"\"\"\n    print(f' - DB CALL: execute_query({sql})')\n\n    cursor = db_conn.cursor()\n\n    cursor.execute(sql)\n    return cursor.fetchall()\n\n\nexecute_query(\"select * from products\")","metadata":{"id":"9e405db8b3f6","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T03:38:49.937404Z","iopub.execute_input":"2025-04-02T03:38:49.937821Z","iopub.status.idle":"2025-04-02T03:38:49.953492Z","shell.execute_reply.started":"2025-04-02T03:38:49.937776Z","shell.execute_reply":"2025-04-02T03:38:49.952491Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Implement function calls\n\nNow you can put it all together in a call to the Gemini API.\n\nFunction calling works by adding specific messages to a chat session. When function schemas are defined and made available to the model and a conversation is started, instead of returning a text response, the model may return a `function_call` instead. When this happens, the client must respond with a `function_response`, indicating the result of the call, and the conversation can continue on as normal.\n\nThis function calling interaction normally happens manually, allowing you, the client, to validate and initiate the call. However the Python SDK also supports **automatic function calling**, where the supplied functions will be automatically invoked. This is a powerful feature and should be used with care, such as when the functions have no [side-effects](https://en.wikipedia.org/wiki/Side_effect_(computer_science)).\n\nHere's the state diagram representing the conversation flow with function calling. With automatic function calling, the bottom row is executed automatically by the Python SDK. With manual function calling, you write the code to run each step individually.\n\n![function calling state diagram](https://codelabs.developers.google.com/static/codelabs/gemini-function-calling/img/gemini-function-calling-overview_1440.png)","metadata":{"id":"ac464dfb35a0"}},{"cell_type":"code","source":"# These are the Python functions defined above.\ndb_tools = [list_tables, describe_table, execute_query]\n\ninstruction = \"\"\"You are a helpful chatbot that can interact with an SQL database\nfor a computer store. You will take the users questions and turn them into SQL\nqueries using the tools available. Once you have the information you need, you will\nanswer the user's question using the data returned.\n\nUse list_tables to see what tables are present, describe_table to understand the\nschema, and execute_query to issue an SQL SELECT query.\"\"\"\n\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n\n# Start a chat with automatic function calling enabled.\nchat = client.chats.create(\n    model=\"gemini-2.0-flash\",\n    config=types.GenerateContentConfig(\n        system_instruction=instruction,\n        tools=db_tools,\n    ),\n)","metadata":{"id":"f4839540066d","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T03:38:49.954953Z","iopub.execute_input":"2025-04-02T03:38:49.955318Z","iopub.status.idle":"2025-04-02T03:38:49.986937Z","shell.execute_reply.started":"2025-04-02T03:38:49.955274Z","shell.execute_reply":"2025-04-02T03:38:49.985876Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now you can engage in a chat conversation where you can ask about the contents of the database.","metadata":{"id":"5f120977f1ee"}},{"cell_type":"code","source":"resp = chat.send_message(\"What is the cheapest product?\")\nprint(f\"\\n{resp.text}\")","metadata":{"id":"111cfb79338b","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T03:38:49.988279Z","iopub.execute_input":"2025-04-02T03:38:49.988601Z","iopub.status.idle":"2025-04-02T03:38:51.882047Z","shell.execute_reply.started":"2025-04-02T03:38:49.98857Z","shell.execute_reply":"2025-04-02T03:38:51.880957Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Explore the chat session and ask your own questions. The 2.0 models are quite capable and can usually answer questions requiring multiple steps.","metadata":{"id":"d67f635191c8"}},{"cell_type":"code","source":"chat = client.chats.create(\n    model=\"gemini-2.0-flash\",\n    config=types.GenerateContentConfig(\n        system_instruction=instruction,\n        tools=db_tools,\n    ),\n)\n\nresponse = chat.send_message('What products should salesperson Alice focus on to round out her portfolio? Explain why.')\nprint(f\"\\n{response.text}\")","metadata":{"id":"647cbcc43993","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T03:38:51.885052Z","iopub.execute_input":"2025-04-02T03:38:51.885376Z","iopub.status.idle":"2025-04-02T03:40:31.155983Z","shell.execute_reply.started":"2025-04-02T03:38:51.885343Z","shell.execute_reply":"2025-04-02T03:40:31.154814Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Inspecting the conversation\n\nTo see the calls that the model makes, and what the client returns in response, you can inspect the chat history. This helper function will print out each turn along with the relevant fields passed or returned.","metadata":{"id":"1f5bb6d9bd6a"}},{"cell_type":"code","source":"import textwrap\n\n\ndef print_chat_turns(chat):\n    \"\"\"Prints out each turn in the chat history, including function calls and responses.\"\"\"\n    for event in chat.get_history():\n        print(f\"{event.role.capitalize()}:\")\n\n        for part in event.parts:\n            if txt := part.text:\n                print(f'  \"{txt}\"')\n            elif fn := part.function_call:\n                args = \", \".join(f\"{key}={val}\" for key, val in fn.args.items())\n                print(f\"  Function call: {fn.name}({args})\")\n            elif resp := part.function_response:\n                print(\"  Function response:\")\n                print(textwrap.indent(str(resp.response['result']), \"    \"))\n\n        print()\n\n\nprint_chat_turns(chat)","metadata":{"id":"639963cc64e2","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T03:40:31.157266Z","iopub.execute_input":"2025-04-02T03:40:31.157548Z","iopub.status.idle":"2025-04-02T03:40:31.165721Z","shell.execute_reply.started":"2025-04-02T03:40:31.15752Z","shell.execute_reply":"2025-04-02T03:40:31.164666Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In this output you can see each of the conversational turns that were made. Note that the model doesn't remember anything outside of the chat history, so you can make changes to the database structure or data and the model will respond without needing any code changes - try this out!","metadata":{"id":"8a17aeb2a3ef"}},{"cell_type":"markdown","source":"## Compositional function calling\n\nA powerful new feature in Gemini 2.0 is the model's ability to compose user-provided function calls together while generating code.\n\nThis means that the model is able to take the available tools, generate code that uses it, and execute it all.\n\nThe feature requires the Live API, so this step uses different setup code than most of the examples you have seen so far. As the Multimodal Live API is a bi-directional streaming service, everything is set up in advance and then executed. This is a little more complex but the result is quite powerful.\n\nFirst define a function that will handle streaming model output. It will stream text output, handle tool-calling and show the generated code that the model writes and executes to fulfill the task.","metadata":{}},{"cell_type":"code","source":"from pprint import pformat\nfrom IPython.display import display, Image, Markdown\n\n\nasync def handle_response(stream, tool_impl=None):\n  \"\"\"Stream output and handle any tool calls during the session.\"\"\"\n  all_responses = []\n\n  async for msg in stream.receive():\n    all_responses.append(msg)\n\n    if text := msg.text:\n      # Output any text chunks that are streamed back.\n      if len(all_responses) < 2 or not all_responses[-2].text:\n        # Display a header if this is the first text chunk.\n        display(Markdown('### Text'))\n\n      print(text, end='')\n\n    elif tool_call := msg.tool_call:\n      # Handle tool-call requests.\n      for fc in tool_call.function_calls:\n        display(Markdown('### Tool call'))\n\n        # Execute the tool and collect the result to return to the model.\n        if callable(tool_impl):\n          try:\n            result = tool_impl(**fc.args)\n          except Exception as e:\n            result = str(e)\n        else:\n          result = 'ok'\n\n        tool_response = types.LiveClientToolResponse(\n            function_responses=[types.FunctionResponse(\n                name=fc.name,\n                id=fc.id,\n                response={'result': result},\n            )]\n        )\n        await stream.send(input=tool_response)\n\n    elif msg.server_content and msg.server_content.model_turn:\n      # Print any messages showing code the model generated and ran.\n\n      for part in msg.server_content.model_turn.parts:\n          if code := part.executable_code:\n            display(Markdown(\n                f'### Code\\n```\\n{code.code}\\n```'))\n\n          elif result := part.code_execution_result:\n            display(Markdown(f'### Result: {result.outcome}\\n'\n                             f'```\\n{pformat(result.output)}\\n```'))\n\n          elif img := part.inline_data:\n            display(Image(img.data))\n\n  print()\n  return all_responses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T03:40:31.1675Z","iopub.execute_input":"2025-04-02T03:40:31.167838Z","iopub.status.idle":"2025-04-02T03:40:31.182426Z","shell.execute_reply.started":"2025-04-02T03:40:31.167805Z","shell.execute_reply":"2025-04-02T03:40:31.181371Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Textual live database chat\n\nNow connect to the model and start a conversation.\n\nThe Live API is a streaming API, so this example is fully pre-scripted and only has a single user input. Despite this, the request still requires the model to perform a bit of back-and-forth to interrogate the database, and you should see the model generate some code that uses the `execute_query` tool in a loop.","metadata":{}},{"cell_type":"code","source":"model = 'gemini-2.0-flash-exp'\nlive_client = genai.Client(api_key=GOOGLE_API_KEY,\n                           http_options=types.HttpOptions(api_version='v1alpha'))\n\n# Wrap the existing execute_query tool you used in the earlier example.\nexecute_query_tool_def = types.FunctionDeclaration.from_callable(\n    client=live_client, callable=execute_query)\n\n# Provide the model with enough information to use the tool, such as describing\n# the database so it understands which SQL syntax to use.\nsys_int = \"\"\"You are a database interface. Use the `execute_query` function\nto answer the users questions by looking up information in the database,\nrunning any necessary queries and responding to the user.\n\nYou need to look up table schema using sqlite3 syntax SQL, then once an\nanswer is found be sure to tell the user. If the user is requesting an\naction, you must also execute the actions.\n\"\"\"\n\nconfig = {\n    \"response_modalities\": [\"TEXT\"],\n    \"system_instruction\": {\"parts\": [{\"text\": sys_int}]},\n    \"tools\": [\n        {\"code_execution\": {}},\n        {\"function_declarations\": [execute_query_tool_def.to_json_dict()]},\n    ],\n}\n\nasync with live_client.aio.live.connect(model=model, config=config) as session:\n\n  message = \"Please generate and insert 5 new rows in the orders table.\"\n  print(f\"> {message}\\n\")\n\n  await session.send(input=message, end_of_turn=True)\n  await handle_response(session, tool_impl=execute_query)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T03:40:31.183667Z","iopub.execute_input":"2025-04-02T03:40:31.183969Z","iopub.status.idle":"2025-04-02T03:40:35.215097Z","shell.execute_reply.started":"2025-04-02T03:40:31.18394Z","shell.execute_reply":"2025-04-02T03:40:35.214161Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In the output from the previous step, you should see a `Code` section that shows code that the model generated in order to complete the task. It will look something like this:\n\n```py\nsql_statements = [ ... ]\n\nfor sql in sql_statements:\n  print(default_api.execute_query(sql))\n```\n\nThe model then runs this code (remotely), calling out to the provided tool when it reaches that part of the code. The `default_api` module contains the tools that you provided.\n\nThis example simply executes in a loop, but the models are capable of more complex interactions with multiple tools, giving you a powerful agent framework that's effectively built in to the Gemini API.","metadata":{}},{"cell_type":"markdown","source":"### Plotting the database\n\nTry out the built-in agent capability with the next example. You may notice the model try to guess the database schema or environment. Often the model will make mistakes, but you can look through the `Text` output and watch as the model inspects the error, tries a new approach and learns from its mistakes.\n\nIf the model doesn't return a plot, try running the cell again.","metadata":{}},{"cell_type":"code","source":"async with live_client.aio.live.connect(model=model, config=config) as session:\n\n  message = \"Can you figure out the number of orders that were made by each of the staff?\"\n\n  print(f\"> {message}\\n\")\n  await session.send(input=message, end_of_turn=True)\n  await handle_response(session, tool_impl=execute_query)\n\n  message = \"Generate and run some code to plot this as a python seaborn chart\"\n\n  print(f\"> {message}\\n\")\n  await session.send(input=message, end_of_turn=True)\n  await handle_response(session, tool_impl=execute_query)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T03:40:35.216532Z","iopub.execute_input":"2025-04-02T03:40:35.217284Z","iopub.status.idle":"2025-04-02T03:40:43.934431Z","shell.execute_reply.started":"2025-04-02T03:40:35.217228Z","shell.execute_reply":"2025-04-02T03:40:43.933445Z"}},"outputs":[],"execution_count":null}]}