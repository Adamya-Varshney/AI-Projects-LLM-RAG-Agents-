{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2157,"sourceType":"datasetVersion","datasetId":18},{"sourceId":11503654,"sourceType":"datasetVersion","datasetId":7212378},{"sourceId":11512089,"sourceType":"datasetVersion","datasetId":7218880}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport google.generativeai as genai\n\nfrom kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\nTAVILY_API_KEY = UserSecretsClient().get_secret(\"TAVILY_API_KEY\")\nOPENAI_API_KEY = UserSecretsClient().get_secret(\"OPENAI_API_KEY\")\n# print(GOOGLE_API_KEY,TAVILY_API_KEY)\n# Set your API keys\nos.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\nos.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\nos.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n\ngenai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:51:13.488302Z","iopub.execute_input":"2025-04-22T11:51:13.489046Z","iopub.status.idle":"2025-04-22T11:51:16.611942Z","shell.execute_reply.started":"2025-04-22T11:51:13.489017Z","shell.execute_reply":"2025-04-22T11:51:16.610906Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport tiktoken","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:51:20.164967Z","iopub.execute_input":"2025-04-22T11:51:20.165319Z","iopub.status.idle":"2025-04-22T11:51:20.170147Z","shell.execute_reply.started":"2025-04-22T11:51:20.165292Z","shell.execute_reply":"2025-04-22T11:51:20.169201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import openai  # For OpenAI API","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:51:20.476594Z","iopub.execute_input":"2025-04-22T11:51:20.476911Z","iopub.status.idle":"2025-04-22T11:51:22.401339Z","shell.execute_reply.started":"2025-04-22T11:51:20.476888Z","shell.execute_reply":"2025-04-22T11:51:22.400007Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"embedding_model = \"text-embedding-3-small\"\nembedding_encoding = \"cl100k_base\"\nmax_tokens = 8000  # the maximum for text-embedding-3-small is 8191","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:51:22.403098Z","iopub.execute_input":"2025-04-22T11:51:22.403620Z","iopub.status.idle":"2025-04-22T11:51:22.407685Z","shell.execute_reply.started":"2025-04-22T11:51:22.403587Z","shell.execute_reply":"2025-04-22T11:51:22.406969Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# load & inspect dataset\ninput_datapath = \"/kaggle/input/reviews/Reviews.csv\"  # to save space, we provide a pre-filtered dataset\ndf = pd.read_csv(input_datapath, index_col=0)\ndf = df[[\"Time\", \"ProductId\", \"UserId\", \"Score\", \"Summary\", \"Text\"]]\ndf = df.dropna()\ndf[\"combined\"] = (\n    \"Title: \" + df.Summary.str.strip() + \"; Content: \" + df.Text.str.strip()\n)\ndf.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:51:22.408888Z","iopub.execute_input":"2025-04-22T11:51:22.409135Z","iopub.status.idle":"2025-04-22T11:51:31.346172Z","shell.execute_reply.started":"2025-04-22T11:51:22.409115Z","shell.execute_reply":"2025-04-22T11:51:31.345505Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# subsample to 1k most recent reviews and remove samples that are too long\ntop_n = 1000\ndf = df.sort_values(\"Time\").tail(top_n * 2)  # first cut to first 2k entries, assuming less than half will be filtered out\ndf.drop(\"Time\", axis=1, inplace=True)\n\nencoding = tiktoken.get_encoding(embedding_encoding)\n\n# omit reviews that are too long to embed\ndf[\"n_tokens\"] = df.combined.apply(lambda x: len(encoding.encode(x)))\ndf = df[df.n_tokens <= max_tokens].tail(top_n)\nlen(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:51:34.593226Z","iopub.execute_input":"2025-04-22T11:51:34.593606Z","iopub.status.idle":"2025-04-22T11:51:36.101294Z","shell.execute_reply.started":"2025-04-22T11:51:34.593581Z","shell.execute_reply":"2025-04-22T11:51:36.100503Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install utils","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:51:36.102820Z","iopub.execute_input":"2025-04-22T11:51:36.103094Z","iopub.status.idle":"2025-04-22T11:51:43.568208Z","shell.execute_reply.started":"2025-04-22T11:51:36.103075Z","shell.execute_reply":"2025-04-22T11:51:43.566910Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys\nsys.path.append(r\"C:\\Users\\Adamy\\utils\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:51:43.569765Z","iopub.execute_input":"2025-04-22T11:51:43.570070Z","iopub.status.idle":"2025-04-22T11:51:43.575533Z","shell.execute_reply.started":"2025-04-22T11:51:43.570041Z","shell.execute_reply":"2025-04-22T11:51:43.574526Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import openai\nimport time\n\n\ndef get_embedding(text: str, model: str = \"text-embedding-3-small\") -> list:\n    \"\"\"Call the OpenAI API to get the embedding for a given text string.\"\"\"\n    text = text.replace(\"\\n\", \" \")\n    try:\n        response = openai.embeddings.create(\n            input=[text],\n            model=model\n        )\n        return response.data[0].embedding\n    except Exception as e:\n        print(f\"Retrying after error: {e}\")\n        time.sleep(3)\n        return get_embedding(text, model=model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:51:43.577095Z","iopub.execute_input":"2025-04-22T11:51:43.577386Z","iopub.status.idle":"2025-04-22T11:51:43.594252Z","shell.execute_reply.started":"2025-04-22T11:51:43.577366Z","shell.execute_reply":"2025-04-22T11:51:43.593260Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ensure you have your API key set in your environment per the README: https://github.com/openai/openai-python#usage\n\n# This may take a few minutes\ndf[\"embedding\"] = df.combined.apply(lambda x: get_embedding(x, model=embedding_model))\ndf.to_csv(\"/kaggle/working/fine_food_reviews_with_embeddings_1k.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:51:47.073253Z","iopub.execute_input":"2025-04-22T11:51:47.073599Z","iopub.status.idle":"2025-04-22T11:56:11.082146Z","shell.execute_reply.started":"2025-04-22T11:51:47.073576Z","shell.execute_reply":"2025-04-22T11:56:11.081245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.read_csv(\"/kaggle/working/fine_food_reviews_with_embeddings_1k.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:56:41.783284Z","iopub.execute_input":"2025-04-22T11:56:41.784159Z","iopub.status.idle":"2025-04-22T11:56:42.157572Z","shell.execute_reply.started":"2025-04-22T11:56:41.784131Z","shell.execute_reply":"2025-04-22T11:56:42.156586Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Question answering using embeddings-based search**","metadata":{}},{"cell_type":"code","source":"# imports\nimport ast  # for converting embeddings saved as strings back to arrays\nfrom openai import OpenAI # for calling the OpenAI API\nimport pandas as pd  # for storing text and embeddings data\nimport tiktoken  # for counting tokens\nimport os # for getting API token from env variable OPENAI_API_KEY\nfrom scipy import spatial  # for calculating vector similarities for search\n\n# create a list of models \nGPT_MODELS = [\"gpt-4o\", \"gpt-4o-mini\"]\n# models\nEMBEDDING_MODEL = \"text-embedding-3-small\"\n\nclient = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:24:17.514333Z","iopub.execute_input":"2025-04-22T10:24:17.514634Z","iopub.status.idle":"2025-04-22T10:24:17.736903Z","shell.execute_reply.started":"2025-04-22T10:24:17.514607Z","shell.execute_reply":"2025-04-22T10:24:17.735924Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install openai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:24:17.738635Z","iopub.execute_input":"2025-04-22T10:24:17.739149Z","iopub.status.idle":"2025-04-22T10:24:21.303389Z","shell.execute_reply.started":"2025-04-22T10:24:17.739121Z","shell.execute_reply":"2025-04-22T10:24:21.302388Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# an example question about the 2022 Olympics\nquery = 'Which athletes won the most number of gold medals in 2024 Summer Olympics?'\n\nresponse = client.chat.completions.create(\n    messages=[\n        {'role': 'system', 'content': 'You answer questions about the 2024 Games or latest events.'},\n        {'role': 'user', 'content': query},\n    ],\n    model=GPT_MODELS[0],\n    temperature=0,\n)\n\nprint(response.choices[0].message.content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:24:21.304582Z","iopub.execute_input":"2025-04-22T10:24:21.304840Z","iopub.status.idle":"2025-04-22T10:24:22.448183Z","shell.execute_reply.started":"2025-04-22T10:24:21.304813Z","shell.execute_reply":"2025-04-22T10:24:22.446995Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# text copied and pasted from: https://en.wikipedia.org/wiki/2024_Summer_Olympics\n# We didn't bother to clean the text, but GPT will still understand it\n# Top few sections are included in the text below\n\nwikipedia_article = \"\"\"2024 Summer Olympics\n\nThe 2024 Summer Olympics (French: Les Jeux Olympiques d'été de 2024), officially the Games of the XXXIII Olympiad (French: Jeux de la XXXIIIe olympiade de l'ère moderne) and branded as Paris 2024, were an international multi-sport event held from 26 July to 11 August 2024 in France, with several events started from 24 July. Paris was the host city, with events (mainly football) held in 16 additional cities spread across metropolitan France, including the sailing centre in the second-largest city of France, Marseille, on the Mediterranean Sea, as well as one subsite for surfing in Tahiti, French Polynesia.[4]\n\nParis was awarded the Games at the 131st IOC Session in Lima, Peru, on 13 September 2017. After multiple withdrawals that left only Paris and Los Angeles in contention, the International Olympic Committee (IOC) approved a process to concurrently award the 2024 and 2028 Summer Olympics to the two remaining candidate cities; both bids were praised for their high technical plans and innovative ways to use a record-breaking number of existing and temporary facilities. Having previously hosted in 1900 and 1924, Paris became the second city ever to host the Summer Olympics three times (after London, which hosted the games in 1908, 1948, and 2012).[5][6] Paris 2024 marked the centenary of Paris 1924 and Chamonix 1924 (the first Winter Olympics), as well as the sixth Olympic Games hosted by France (three Summer Olympics and three Winter Olympics) and the first with this distinction since the 1992 Winter Games in Albertville. The Summer Games returned to the traditional four-year Olympiad cycle, after the 2020 edition was postponed to 2021 due to the COVID-19 pandemic.\n\nParis 2024 featured the debut of breaking as an Olympic sport,[7] and was the final Olympic Games held during the IOC presidency of Thomas Bach.[8] The 2024 Games were expected to cost €9 billion.[9][10][11] The opening ceremony was held outside of a stadium for the first time in modern Olympic history, as athletes were paraded by boat along the Seine. Paris 2024 was the first Olympics in history to reach full gender parity on the field of play, with equal numbers of male and female athletes.[12]\n\nThe United States topped the medal table for the fourth consecutive Summer Games and 19th time overall, with 40 gold and 126 total medals.[13] \nChina tied with the United States on gold (40), but finished second due to having fewer silvers; the nation won 91 medals overall. \nThis is the first time a gold medal tie among the two most successful nations has occurred in Summer Olympic history.[14] Japan finished third with 20 gold medals and sixth in the overall medal count. Australia finished fourth with 18 gold medals and fifth in the overall medal count. The host nation, France, finished fifth with 16 gold and 64 total medals, and fourth in the overall medal count. Dominica, Saint Lucia, Cape Verde and Albania won their first-ever Olympic medals, the former two both being gold, with Botswana and Guatemala also winning their first-ever gold medals. \nThe Refugee Olympic Team also won their first-ever medal, a bronze in boxing. At the conclusion of the games, despite some controversies throughout relating to politics, logistics and conditions in the Olympic Village, the Games were considered a success by the press, Parisians and observers.[a] The Paris Olympics broke all-time records for ticket sales, with more than 9.5 million tickets sold (12.1 million including the Paralympic Games).[15]\n\nMedal table\nMain article: 2024 Summer Olympics medal table\nSee also: List of 2024 Summer Olympics medal winners\nKey\n ‡  Changes in medal standings (see below)\n\n  *   Host nation (France)\n\n2024 Summer Olympics medal table[171][B][C]\nRank\tNOC\tGold\tSilver\tBronze\tTotal\n1\t United States‡\t40\t44\t42\t126\n2\t China\t40\t27\t24\t91\n3\t Japan\t20\t12\t13\t45\n4\t Australia\t18\t19\t16\t53\n5\t France*\t16\t26\t22\t64\n6\t Netherlands\t15\t7\t12\t34\n7\t Great Britain\t14\t22\t29\t65\n8\t South Korea\t13\t9\t10\t32\n9\t Italy\t12\t13\t15\t40\n10\t Germany\t12\t13\t8\t33\n11–91\tRemaining NOCs\t129\t138\t194\t461\nTotals (91 entries)\t329\t330\t385\t1,044\n\nPodium sweeps\nThere was one podium sweep during the games:\n\nDate\tSport\tEvent\tTeam\tGold\tSilver\tBronze\tRef\n2 August\tCycling\tMen's BMX race\t France\tJoris Daudet\tSylvain André\tRomain Mahieu\t[176]\n\n\nMedals\nMedals from the Games, with a piece of the Eiffel Tower\nThe President of the Paris 2024 Olympic Organizing Committee, Tony Estanguet, unveiled the Olympic and Paralympic medals for the Games in February 2024, which on the obverse featured embedded hexagon-shaped tokens of scrap iron that had been taken from the original construction of the Eiffel Tower, with the logo of the Games engraved into it.[41] Approximately 5,084 medals would be produced by the French mint Monnaie de Paris, and were designed by Chaumet, a luxury jewellery firm based in Paris.[42]\n\nThe reverse of the medals features Nike, the Greek goddess of victory, inside the Panathenaic Stadium which hosted the first modern Olympics in 1896. Parthenon and the Eiffel Tower can also be seen in the background on both sides of the medal.[43] Each medal weighs 455–529 g (16–19 oz), has a diameter of 85 mm (3.3 in) and is 9.2 mm (0.36 in) thick.[44] The gold medals are made with 98.8 percent silver and 1.13 percent gold, while the bronze medals are made up with copper, zinc, and tin.[45]\n\n\nOpening ceremony\nMain article: 2024 Summer Olympics opening ceremony\n\nPyrotechnics at the Pont d'Austerlitz marking the start of the Parade of Nations\n\nThe cauldron flying above the Tuileries Garden during the games. LEDs and aerosol produced the illusion of fire, while the Olympic flame itself was kept in a small lantern nearby\nThe opening ceremony began at 19:30 CEST (17:30 GMT) on 26 July 2024.[124] Directed by Thomas Jolly,[125][126][127] it was the first Summer Olympics opening ceremony to be held outside the traditional stadium setting (and the second ever after the 2018 Youth Olympic Games one, held at Plaza de la República in Buenos Aires); the parade of athletes was conducted as a boat parade along the Seine from Pont d'Austerlitz to Pont d'Iéna, and cultural segments took place at various landmarks along the route.[128] Jolly stated that the ceremony would highlight notable moments in the history of France, with an overall theme of love and \"shared humanity\".[128] The athletes then attended the official protocol at Jardins du Trocadéro, in front of the Eiffel Tower.[129] Approximately 326,000 tickets were sold for viewing locations along the Seine, 222,000 of which were distributed primarily to the Games' volunteers, youth and low-income families, among others.[130]\n\nThe ceremony featured music performances by American musician Lady Gaga,[131] French-Malian singer Aya Nakamura, heavy metal band Gojira and soprano Marina Viotti [fr],[132] Axelle Saint-Cirel (who sang the French national anthem \"La Marseillaise\" atop the Grand Palais),[133] rapper Rim'K,[134] Philippe Katerine (who portrayed the Greek god Dionysus), Juliette Armanet and Sofiane Pamart, and was closed by Canadian singer Céline Dion.[132] The Games were formally opened by president Emmanuel Macron.[135]\n\nThe Olympics and Paralympics cauldron was lit by Guadeloupean judoka Teddy Riner and sprinter Marie-José Pérec; it had a hot air balloon-inspired design topped by a 30-metre-tall (98 ft) helium sphere, and was allowed to float into the air above the Tuileries Garden at night. For the first time, the cauldron was not illuminated through combustion; the flames were simulated by an LED lighting system and aerosol water jets.[136]\n\nControversy ensued at the opening ceremony when a segment was interpreted by some as a parody of the Last Supper. The organisers apologised for any offence caused.[137] The Olympic World Library and fact-checkers would later debunk the interpretation that the segment was a parody of the Last Supper. The Olympic flag was also raised upside down.[138][139]\n\nDuring the day of the opening ceremony, there were reports of a blackout in Paris, although this was later debunked.[140]\n\nClosing ceremony\n\n\nThe ceremony and final fireworks\nMain article: 2024 Summer Olympics closing ceremony\nThe closing ceremony was held at Stade de France on 11 August 2024, and thus marked the first time in any Olympic edition since Sarajevo 1984 that opening and closing ceremonies were held in different locations.[127] Titled \"Records\", the ceremony was themed around a dystopian future, where the Olympic Games have disappeared, and a group of aliens reinvent it. It featured more than a hundred performers, including acrobats, dancers and circus artists.[158] American actor Tom Cruise also appeared with American performers Red Hot Chili Peppers, Billie Eilish, Snoop Dogg, and H.E.R. during the LA28 Handover Celebration portion of the ceremony.[159][160] The Antwerp Ceremony, in which the Olympic flag was handed to Los Angeles, the host city of the 2028 Summer Olympics, was produced by Ben Winston and his studio Fulwell 73.[161]\n\n\nSecurity\nFrance reached an agreement with Europol and the UK Home Office to help strengthen security and \"facilitate operational information exchange and international law enforcement cooperation\" during the Games.[46] The agreement included a plan to deploy more drones and sea barriers to prevent small boats from crossing the Channel illegally.[47] The British Army would also provide support by deploying Starstreak surface-to-air missile units for air security.[48] To prepare for the Games, the Paris police held inspections and rehearsals in their bomb disposal unit, similar to their preparations for the 2023 Rugby World Cup at the Stade de France.[49]\n\nAs part of a visit to France by Qatari Emir Sheikh Tamim bin Hamad Al-Thani, several agreements were signed between the two nations to enhance security for the Olympics.[50] In preparation for the significant security demands and counterterrorism measures, Poland pledged to contribute security troops, including sniffer dog handlers, to support international efforts aimed at ensuring the safety of the Games.[51][52] The Qatari Minister of Interior and Commander of Lekhwiya (the Qatari security forces) convened a meeting on 3 April 2024 to discuss security operations ahead of the Olympics, with officials and security leaders in attendance, including Nasser Al-Khelaifi and Sheikh Jassim bin Mansour Al Thani.[53] A week before the opening ceremony, the Lekhwiya were reported to have been deployed in Paris on 16 July 2024.[54]\n\nIn the weeks running up to the opening of the Paris Olympics, it was reported that police officers would be deployed from Belgium,[55] Brazil,[56] Canada (through the RCMP/OPP/CPS/SQ),[57][58][59] Cyprus,[60] the Czech Republic,[61] Denmark,[62] Estonia,[63][64] Finland,[65] Germany (through Bundespolizei[66][67]/NRW Police[68]),[69] India,[70][71] Ireland,[72] Italy,[73] Luxembourg,[74] Morocco,[75] Netherlands,[76] Norway,[58] Poland,[77] Portugal,[78] Slovakia,[79] South Korea,[80][81] Spain (through the CNP/GC),[82] Sweden,[83] the UAE,[84] the UK,[49] and the US (through the LAPD,[85] LASD,[86] NYPD,[87] and the Fairfax County Police Department[88]), with more than 40 countries providing police assistance to their French counterparts.[89][90]\n\nSecurity concerns impacted the plans that had been announced for the opening ceremony, which was to take place as a public event along the Seine; the expected attendance was reduced by half from an estimated 600,000 to 300,000, with plans for free viewing locations now being by invitation only. In April 2024, after Islamic State claimed responsibility for the Crocus City Hall attack in March, and made several threats against the UEFA Champions League quarter-finals, French president Emmanuel Macron indicated that the opening ceremony could be scaled back or re-located if necessary.[91][92][93] French authorities had placed roughly 75,000 police and military officials on the streets of Paris in the lead-up to the Games.[94]\n\nFollowing the end of the Games, the national counterterrorism prosecutor, Olivier Christen, revealed that French authorities foiled three terror plots meant to attack the Olympic and Paralympic Games, resulting in the arrest of five suspects.[95]\n\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:24:22.449197Z","iopub.execute_input":"2025-04-22T10:24:22.449454Z","iopub.status.idle":"2025-04-22T10:24:22.460055Z","shell.execute_reply.started":"2025-04-22T10:24:22.449434Z","shell.execute_reply":"2025-04-22T10:24:22.459134Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = f\"\"\"Use the below article on the 2024 Summer Olympics to answer the subsequent question. If the answer cannot be found, write \"I don't know.\"\n\nArticle:\n\\\"\\\"\\\"\n{wikipedia_article}\n\\\"\\\"\\\"\n\nQuestion: Which countries won the maximum number of gold, silver and bronze medals respectively at 2024 Summer Olympics? List the countries in the order of gold, silver and bronze medals.\"\"\"\n\nresponse = client.chat.completions.create(\n    messages=[\n        {'role': 'system', 'content': 'You answer questions about the recent events.'},\n        {'role': 'user', 'content': query},\n    ],\n    model=GPT_MODELS[0],\n    temperature=0,\n)\n\nprint(response.choices[0].message.content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:24:22.460963Z","iopub.execute_input":"2025-04-22T10:24:22.461237Z","iopub.status.idle":"2025-04-22T10:24:24.022292Z","shell.execute_reply.started":"2025-04-22T10:24:22.461210Z","shell.execute_reply":"2025-04-22T10:24:24.021398Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Automate this knowledge insertion with embeddings-based search.**","metadata":{}},{"cell_type":"code","source":"pip install openai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:24:24.023342Z","iopub.execute_input":"2025-04-22T10:24:24.024159Z","iopub.status.idle":"2025-04-22T10:24:27.567311Z","shell.execute_reply.started":"2025-04-22T10:24:24.024133Z","shell.execute_reply":"2025-04-22T10:24:27.566102Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# imports\nimport mwclient  # for downloading example Wikipedia articles\nimport mwparserfromhell  # for splitting Wikipedia articles into sections\nfrom openai import OpenAI  # for generating embeddings\nimport os  # for environment variables\nimport pandas as pd  # for DataFrames to store article sections and embeddings\nimport re  # for cutting <ref> links out of Wikipedia articles\nimport tiktoken  # for counting tokens\n\nclient = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"<your OpenAI API key if not set as env var>\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:28:44.653989Z","iopub.execute_input":"2025-04-22T10:28:44.654366Z","iopub.status.idle":"2025-04-22T10:28:44.740921Z","shell.execute_reply.started":"2025-04-22T10:28:44.654334Z","shell.execute_reply":"2025-04-22T10:28:44.739976Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install mwclient","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:26:03.745614Z","iopub.execute_input":"2025-04-22T10:26:03.745946Z","iopub.status.idle":"2025-04-22T10:26:07.626845Z","shell.execute_reply.started":"2025-04-22T10:26:03.745922Z","shell.execute_reply":"2025-04-22T10:26:07.625674Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install mwclient mwparserfromhell tiktoken openai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:28:37.977220Z","iopub.execute_input":"2025-04-22T10:28:37.977547Z","iopub.status.idle":"2025-04-22T10:28:42.129106Z","shell.execute_reply.started":"2025-04-22T10:28:37.977523Z","shell.execute_reply":"2025-04-22T10:28:42.127931Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# get Wikipedia pages about the 2022 Winter Olympics\n\nCATEGORY_TITLE = \"Category:2022 Winter Olympics\"\nWIKI_SITE = \"en.wikipedia.org\"\n\n\ndef titles_from_category(\n    category: mwclient.listing.Category, max_depth: int\n) -> set[str]:\n    \"\"\"Return a set of page titles in a given Wiki category and its subcategories.\"\"\"\n    titles = set()\n    for cm in category.members():\n        if type(cm) == mwclient.page.Page:\n            # ^type() used instead of isinstance() to catch match w/ no inheritance\n            titles.add(cm.name)\n        elif isinstance(cm, mwclient.listing.Category) and max_depth > 0:\n            deeper_titles = titles_from_category(cm, max_depth=max_depth - 1)\n            titles.update(deeper_titles)\n    return titles\n\n\nsite = mwclient.Site(WIKI_SITE)\ncategory_page = site.pages[CATEGORY_TITLE]\ntitles = titles_from_category(category_page, max_depth=1)\n# ^note: max_depth=1 means we go one level deep in the category tree\nprint(f\"Found {len(titles)} article titles in {CATEGORY_TITLE}.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:28:49.084362Z","iopub.execute_input":"2025-04-22T10:28:49.084748Z","iopub.status.idle":"2025-04-22T10:28:50.523529Z","shell.execute_reply.started":"2025-04-22T10:28:49.084718Z","shell.execute_reply":"2025-04-22T10:28:50.522586Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# define functions to split Wikipedia pages into sections\n\nSECTIONS_TO_IGNORE = [\n    \"See also\",\n    \"References\",\n    \"External links\",\n    \"Further reading\",\n    \"Footnotes\",\n    \"Bibliography\",\n    \"Sources\",\n    \"Citations\",\n    \"Literature\",\n    \"Footnotes\",\n    \"Notes and references\",\n    \"Photo gallery\",\n    \"Works cited\",\n    \"Photos\",\n    \"Gallery\",\n    \"Notes\",\n    \"References and sources\",\n    \"References and notes\",\n]\n\n\ndef all_subsections_from_section(\n    section: mwparserfromhell.wikicode.Wikicode,\n    parent_titles: list[str],\n    sections_to_ignore: set[str],\n) -> list[tuple[list[str], str]]:\n    \"\"\"\n    From a Wikipedia section, return a flattened list of all nested subsections.\n    Each subsection is a tuple, where:\n        - the first element is a list of parent subtitles, starting with the page title\n        - the second element is the text of the subsection (but not any children)\n    \"\"\"\n    headings = [str(h) for h in section.filter_headings()]\n    title = headings[0]\n    if title.strip(\"=\" + \" \") in sections_to_ignore:\n        # ^wiki headings are wrapped like \"== Heading ==\"\n        return []\n    titles = parent_titles + [title]\n    full_text = str(section)\n    section_text = full_text.split(title)[1]\n    if len(headings) == 1:\n        return [(titles, section_text)]\n    else:\n        first_subtitle = headings[1]\n        section_text = section_text.split(first_subtitle)[0]\n        results = [(titles, section_text)]\n        for subsection in section.get_sections(levels=[len(titles) + 1]):\n            results.extend(all_subsections_from_section(subsection, titles, sections_to_ignore))\n        return results\n\n\ndef all_subsections_from_title(\n    title: str,\n    sections_to_ignore: set[str] = SECTIONS_TO_IGNORE,\n    site_name: str = WIKI_SITE,\n) -> list[tuple[list[str], str]]:\n    \"\"\"From a Wikipedia page title, return a flattened list of all nested subsections.\n    Each subsection is a tuple, where:\n        - the first element is a list of parent subtitles, starting with the page title\n        - the second element is the text of the subsection (but not any children)\n    \"\"\"\n    site = mwclient.Site(site_name)\n    page = site.pages[title]\n    text = page.text()\n    parsed_text = mwparserfromhell.parse(text)\n    headings = [str(h) for h in parsed_text.filter_headings()]\n    if headings:\n        summary_text = str(parsed_text).split(headings[0])[0]\n    else:\n        summary_text = str(parsed_text)\n    results = [([title], summary_text)]\n    for subsection in parsed_text.get_sections(levels=[2]):\n        results.extend(all_subsections_from_section(subsection, [title], sections_to_ignore))\n    return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:28:53.896917Z","iopub.execute_input":"2025-04-22T10:28:53.897266Z","iopub.status.idle":"2025-04-22T10:28:53.914361Z","shell.execute_reply.started":"2025-04-22T10:28:53.897238Z","shell.execute_reply":"2025-04-22T10:28:53.912932Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# split pages into sections\n# may take ~1 minute per 100 articles\nwikipedia_sections = []\nfor title in titles:\n    wikipedia_sections.extend(all_subsections_from_title(title))\nprint(f\"Found {len(wikipedia_sections)} sections in {len(titles)} pages.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:29:02.469325Z","iopub.execute_input":"2025-04-22T10:29:02.469664Z","iopub.status.idle":"2025-04-22T10:30:19.472574Z","shell.execute_reply.started":"2025-04-22T10:29:02.469621Z","shell.execute_reply":"2025-04-22T10:30:19.471648Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# clean text\ndef clean_section(section: tuple[list[str], str]) -> tuple[list[str], str]:\n    \"\"\"\n    Return a cleaned up section with:\n        - <ref>xyz</ref> patterns removed\n        - leading/trailing whitespace removed\n    \"\"\"\n    titles, text = section\n    text = re.sub(r\"<ref.*?</ref>\", \"\", text)\n    text = text.strip()\n    return (titles, text)\n\n\nwikipedia_sections = [clean_section(ws) for ws in wikipedia_sections]\n\n# filter out short/blank sections\ndef keep_section(section: tuple[list[str], str]) -> bool:\n    \"\"\"Return True if the section should be kept, False otherwise.\"\"\"\n    titles, text = section\n    if len(text) < 16:\n        return False\n    else:\n        return True\n\n\noriginal_num_sections = len(wikipedia_sections)\nwikipedia_sections = [ws for ws in wikipedia_sections if keep_section(ws)]\nprint(f\"Filtered out {original_num_sections-len(wikipedia_sections)} sections, leaving {len(wikipedia_sections)} sections.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:30:51.445006Z","iopub.execute_input":"2025-04-22T10:30:51.445343Z","iopub.status.idle":"2025-04-22T10:30:51.491280Z","shell.execute_reply.started":"2025-04-22T10:30:51.445320Z","shell.execute_reply":"2025-04-22T10:30:51.490359Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print example data\nfor ws in wikipedia_sections[:5]:\n    print(ws[0])\n    display(ws[1][:77] + \"...\")\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:30:56.776640Z","iopub.execute_input":"2025-04-22T10:30:56.777411Z","iopub.status.idle":"2025-04-22T10:30:56.791390Z","shell.execute_reply.started":"2025-04-22T10:30:56.777384Z","shell.execute_reply":"2025-04-22T10:30:56.790581Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"GPT_MODEL = \"gpt-4o-mini\"  # only matters insofar as it selects which tokenizer to use\n\n\ndef num_tokens(text: str, model: str = GPT_MODEL) -> int:\n    \"\"\"Return the number of tokens in a string.\"\"\"\n    encoding = tiktoken.encoding_for_model(model)\n    return len(encoding.encode(text))\n\n\ndef halved_by_delimiter(string: str, delimiter: str = \"\\n\") -> list[str, str]:\n    \"\"\"Split a string in two, on a delimiter, trying to balance tokens on each side.\"\"\"\n    chunks = string.split(delimiter)\n    if len(chunks) == 1:\n        return [string, \"\"]  # no delimiter found\n    elif len(chunks) == 2:\n        return chunks  # no need to search for halfway point\n    else:\n        total_tokens = num_tokens(string)\n        halfway = total_tokens // 2\n        best_diff = halfway\n        for i, chunk in enumerate(chunks):\n            left = delimiter.join(chunks[: i + 1])\n            left_tokens = num_tokens(left)\n            diff = abs(halfway - left_tokens)\n            if diff >= best_diff:\n                break\n            else:\n                best_diff = diff\n        left = delimiter.join(chunks[:i])\n        right = delimiter.join(chunks[i:])\n        return [left, right]\n\n\ndef truncated_string(\n    string: str,\n    model: str,\n    max_tokens: int,\n    print_warning: bool = True,\n) -> str:\n    \"\"\"Truncate a string to a maximum number of tokens.\"\"\"\n    encoding = tiktoken.encoding_for_model(model)\n    encoded_string = encoding.encode(string)\n    truncated_string = encoding.decode(encoded_string[:max_tokens])\n    if print_warning and len(encoded_string) > max_tokens:\n        print(f\"Warning: Truncated string from {len(encoded_string)} tokens to {max_tokens} tokens.\")\n    return truncated_string\n\n\ndef split_strings_from_subsection(\n    subsection: tuple[list[str], str],\n    max_tokens: int = 1000,\n    model: str = GPT_MODEL,\n    max_recursion: int = 5,\n) -> list[str]:\n    \"\"\"\n    Split a subsection into a list of subsections, each with no more than max_tokens.\n    Each subsection is a tuple of parent titles [H1, H2, ...] and text (str).\n    \"\"\"\n    titles, text = subsection\n    string = \"\\n\\n\".join(titles + [text])\n    num_tokens_in_string = num_tokens(string)\n    # if length is fine, return string\n    if num_tokens_in_string <= max_tokens:\n        return [string]\n    # if recursion hasn't found a split after X iterations, just truncate\n    elif max_recursion == 0:\n        return [truncated_string(string, model=model, max_tokens=max_tokens)]\n    # otherwise, split in half and recurse\n    else:\n        titles, text = subsection\n        for delimiter in [\"\\n\\n\", \"\\n\", \". \"]:\n            left, right = halved_by_delimiter(text, delimiter=delimiter)\n            if left == \"\" or right == \"\":\n                # if either half is empty, retry with a more fine-grained delimiter\n                continue\n            else:\n                # recurse on each half\n                results = []\n                for half in [left, right]:\n                    half_subsection = (titles, half)\n                    half_strings = split_strings_from_subsection(\n                        half_subsection,\n                        max_tokens=max_tokens,\n                        model=model,\n                        max_recursion=max_recursion - 1,\n                    )\n                    results.extend(half_strings)\n                return results\n    # otherwise no split was found, so just truncate (should be very rare)\n    return [truncated_string(string, model=model, max_tokens=max_tokens)]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:31:01.675564Z","iopub.execute_input":"2025-04-22T10:31:01.676250Z","iopub.status.idle":"2025-04-22T10:31:01.690018Z","shell.execute_reply.started":"2025-04-22T10:31:01.676220Z","shell.execute_reply":"2025-04-22T10:31:01.688924Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# split sections into chunks\nMAX_TOKENS = 1600\nwikipedia_strings = []\nfor section in wikipedia_sections:\n    wikipedia_strings.extend(split_strings_from_subsection(section, max_tokens=MAX_TOKENS))\n\nprint(f\"{len(wikipedia_sections)} Wikipedia sections split into {len(wikipedia_strings)} strings.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:31:09.296653Z","iopub.execute_input":"2025-04-22T10:31:09.296969Z","iopub.status.idle":"2025-04-22T10:31:23.145822Z","shell.execute_reply.started":"2025-04-22T10:31:09.296945Z","shell.execute_reply":"2025-04-22T10:31:23.144747Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print example data\nprint(wikipedia_strings[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:31:40.728570Z","iopub.execute_input":"2025-04-22T10:31:40.728929Z","iopub.status.idle":"2025-04-22T10:31:40.733841Z","shell.execute_reply.started":"2025-04-22T10:31:40.728885Z","shell.execute_reply":"2025-04-22T10:31:40.732793Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EMBEDDING_MODEL = \"text-embedding-3-small\"\nBATCH_SIZE = 1000  # you can submit up to 2048 embedding inputs per request\n\nembeddings = []\nfor batch_start in range(0, len(wikipedia_strings), BATCH_SIZE):\n    batch_end = batch_start + BATCH_SIZE\n    batch = wikipedia_strings[batch_start:batch_end]\n    print(f\"Batch {batch_start} to {batch_end-1}\")\n    response = client.embeddings.create(model=EMBEDDING_MODEL, input=batch)\n    for i, be in enumerate(response.data):\n        assert i == be.index  # double check embeddings are in same order as input\n    batch_embeddings = [e.embedding for e in response.data]\n    embeddings.extend(batch_embeddings)\n\ndf = pd.DataFrame({\"text\": wikipedia_strings, \"embedding\": embeddings})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:31:44.081443Z","iopub.execute_input":"2025-04-22T10:31:44.081771Z","iopub.status.idle":"2025-04-22T10:31:53.828591Z","shell.execute_reply.started":"2025-04-22T10:31:44.081745Z","shell.execute_reply":"2025-04-22T10:31:53.827903Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# save document chunks and embeddings\n\nSAVE_PATH = \"/kaggle/working/winter_olympics_2022.csv\"\n\ndf.to_csv(SAVE_PATH, index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:31:56.861315Z","iopub.execute_input":"2025-04-22T10:31:56.861734Z","iopub.status.idle":"2025-04-22T10:32:01.660199Z","shell.execute_reply.started":"2025-04-22T10:31:56.861702Z","shell.execute_reply":"2025-04-22T10:32:01.659049Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.read_csv('winter_olympics_2022.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:32:10.744106Z","iopub.execute_input":"2025-04-22T10:32:10.745173Z","iopub.status.idle":"2025-04-22T10:32:11.712153Z","shell.execute_reply.started":"2025-04-22T10:32:10.745140Z","shell.execute_reply":"2025-04-22T10:32:11.711273Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# download pre-chunked text and pre-computed embeddings\n# this file is ~200 MB, so may take a minute depending on your connection speed\nembeddings_path = \"winter_olympics_2022.csv\"\n\ndf = pd.read_csv(embeddings_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:32:13.514545Z","iopub.execute_input":"2025-04-22T10:32:13.515047Z","iopub.status.idle":"2025-04-22T10:32:14.462019Z","shell.execute_reply.started":"2025-04-22T10:32:13.515006Z","shell.execute_reply":"2025-04-22T10:32:14.460963Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:32:17.538116Z","iopub.execute_input":"2025-04-22T10:32:17.538455Z","iopub.status.idle":"2025-04-22T10:32:17.550189Z","shell.execute_reply.started":"2025-04-22T10:32:17.538430Z","shell.execute_reply":"2025-04-22T10:32:17.549332Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# download pre-chunked text and pre-computed embeddings\n# this file is ~200 MB, so may take a minute depending on your connection speed\nembeddings_path = \"/kaggle/working/winter_olympics_2022.csv\"\n\ndf = pd.read_csv(embeddings_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:32:21.485833Z","iopub.execute_input":"2025-04-22T10:32:21.486173Z","iopub.status.idle":"2025-04-22T10:32:22.423570Z","shell.execute_reply.started":"2025-04-22T10:32:21.486147Z","shell.execute_reply":"2025-04-22T10:32:22.422755Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# convert embeddings from CSV str type back to list type\ndf['embedding'] = df['embedding'].apply(ast.literal_eval)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:32:28.675869Z","iopub.execute_input":"2025-04-22T10:32:28.676248Z","iopub.status.idle":"2025-04-22T10:32:43.003174Z","shell.execute_reply.started":"2025-04-22T10:32:28.676220Z","shell.execute_reply":"2025-04-22T10:32:43.002268Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:33:05.443611Z","iopub.execute_input":"2025-04-22T10:33:05.443897Z","iopub.status.idle":"2025-04-22T10:33:05.463033Z","shell.execute_reply.started":"2025-04-22T10:33:05.443877Z","shell.execute_reply":"2025-04-22T10:33:05.462118Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# search function\ndef strings_ranked_by_relatedness(\n    query: str,\n    df: pd.DataFrame,\n    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n    top_n: int = 100\n) -> tuple[list[str], list[float]]:\n    \"\"\"Returns a list of strings and relatednesses, sorted from most related to least.\"\"\"\n    query_embedding_response = client.embeddings.create(\n        model=EMBEDDING_MODEL,\n        input=query,\n    )\n    query_embedding = query_embedding_response.data[0].embedding\n    strings_and_relatednesses = [\n        (row[\"text\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n        for i, row in df.iterrows()\n    ]\n    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n    strings, relatednesses = zip(*strings_and_relatednesses)\n    return strings[:top_n], relatednesses[:top_n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:33:05.575923Z","iopub.execute_input":"2025-04-22T10:33:05.576691Z","iopub.status.idle":"2025-04-22T10:33:05.583510Z","shell.execute_reply.started":"2025-04-22T10:33:05.576659Z","shell.execute_reply":"2025-04-22T10:33:05.582351Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# examples\nstrings, relatednesses = strings_ranked_by_relatedness(\"curling gold medal\", df, top_n=5)\nfor string, relatedness in zip(strings, relatednesses):\n    print(f\"{relatedness=:.3f}\")\n    display(string)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:33:05.970980Z","iopub.execute_input":"2025-04-22T10:33:05.972337Z","iopub.status.idle":"2025-04-22T10:33:06.847440Z","shell.execute_reply.started":"2025-04-22T10:33:05.972292Z","shell.execute_reply":"2025-04-22T10:33:06.846504Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def num_tokens(text: str, model: str = GPT_MODELS[0]) -> int:\n    \"\"\"Return the number of tokens in a string.\"\"\"\n    encoding = tiktoken.encoding_for_model(model)\n    return len(encoding.encode(text))\n\n\ndef query_message(\n    query: str,\n    df: pd.DataFrame,\n    model: str,\n    token_budget: int\n) -> str:\n    \"\"\"Return a message for GPT, with relevant source texts pulled from a dataframe.\"\"\"\n    strings, relatednesses = strings_ranked_by_relatedness(query, df)\n    introduction = 'Use the below articles on the 2022 Winter Olympics to answer the subsequent question. If the answer cannot be found in the articles, write \"I could not find an answer.\"'\n    question = f\"\\n\\nQuestion: {query}\"\n    message = introduction\n    for string in strings:\n        next_article = f'\\n\\nWikipedia article section:\\n\"\"\"\\n{string}\\n\"\"\"'\n        if (\n            num_tokens(message + next_article + question, model=model)\n            > token_budget\n        ):\n            break\n        else:\n            message += next_article\n    return message + question\n\n\ndef ask(\n    query: str,\n    df: pd.DataFrame = df,\n    model: str = GPT_MODELS[0],\n    token_budget: int = 4096 - 500,\n    print_message: bool = False,\n) -> str:\n    \"\"\"Answers a query using GPT and a dataframe of relevant texts and embeddings.\"\"\"\n    message = query_message(query, df, model=model, token_budget=token_budget)\n    if print_message:\n        print(message)\n    messages = [\n        {\"role\": \"system\", \"content\": \"You answer questions about the 2022 Winter Olympics.\"},\n        {\"role\": \"user\", \"content\": message},\n    ]\n    response = client.chat.completions.create(\n        model=model,\n        messages=messages,\n        temperature=0\n    )\n    response_message = response.choices[0].message.content\n    return response_message\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:33:06.848905Z","iopub.execute_input":"2025-04-22T10:33:06.849213Z","iopub.status.idle":"2025-04-22T10:33:06.857877Z","shell.execute_reply.started":"2025-04-22T10:33:06.849192Z","shell.execute_reply":"2025-04-22T10:33:06.856779Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ask('Which athletes won the gold medal in curling at the 2022 Winter Olympics?')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:33:06.870933Z","iopub.execute_input":"2025-04-22T10:33:06.871385Z","iopub.status.idle":"2025-04-22T10:33:08.760813Z","shell.execute_reply.started":"2025-04-22T10:33:06.871359Z","shell.execute_reply":"2025-04-22T10:33:08.759818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# set print_message=True to see the source text GPT was working off of\nask('Which athletes won the gold medal in curling at the 2022 Winter Olympics?', print_message=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:33:08.762040Z","iopub.execute_input":"2025-04-22T10:33:08.762348Z","iopub.status.idle":"2025-04-22T10:33:11.240530Z","shell.execute_reply.started":"2025-04-22T10:33:08.762323Z","shell.execute_reply":"2025-04-22T10:33:11.239692Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ask('Which athletes won the gold medal in curling at the 2022 Winter Olympics?', model=GPT_MODELS[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:33:23.056206Z","iopub.execute_input":"2025-04-22T10:33:23.056513Z","iopub.status.idle":"2025-04-22T10:33:25.750196Z","shell.execute_reply.started":"2025-04-22T10:33:23.056492Z","shell.execute_reply":"2025-04-22T10:33:25.749212Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Text search using embeddings**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom ast import literal_eval\n\ndatafile_path = \"/kaggle/working//fine_food_reviews_with_embeddings_1k.csv\"\n\ndf = pd.read_csv(datafile_path)\ndf[\"embedding\"] = df.embedding.apply(literal_eval).apply(np.array)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:33:25.751674Z","iopub.execute_input":"2025-04-22T10:33:25.751990Z","iopub.status.idle":"2025-04-22T10:33:33.568308Z","shell.execute_reply.started":"2025-04-22T10:33:25.751962Z","shell.execute_reply":"2025-04-22T10:33:33.567174Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df[\"embedding\"].iloc[0])  # will show a NumPy array","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:33:33.569331Z","iopub.execute_input":"2025-04-22T10:33:33.569612Z","iopub.status.idle":"2025-04-22T10:33:33.575912Z","shell.execute_reply.started":"2025-04-22T10:33:33.569590Z","shell.execute_reply":"2025-04-22T10:33:33.574957Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from numpy.linalg import norm\n\ndef cosine_similarity(a, b):\n    return np.dot(a, b) / (norm(a) * norm(b))\n\n# Example: similarity between first and second review\n#cosine_similarity(df[\"embedding\"].iloc[0], df[\"embedding\"].iloc[1])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:33:33.577927Z","iopub.execute_input":"2025-04-22T10:33:33.578274Z","iopub.status.idle":"2025-04-22T10:33:33.607796Z","shell.execute_reply.started":"2025-04-22T10:33:33.578247Z","shell.execute_reply":"2025-04-22T10:33:33.607147Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# search through the reviews for a specific product\ndef search_reviews(df, product_description, n=3, pprint=True):\n    product_embedding = get_embedding(\n        product_description,\n        model=\"text-embedding-3-small\"\n    )\n    df[\"similarity\"] = df.embedding.apply(lambda x: cosine_similarity(x, product_embedding))\n\n    results = (\n        df.sort_values(\"similarity\", ascending=False)\n        .head(n)\n        .combined.str.replace(\"Title: \", \"\")\n        .str.replace(\"; Content:\", \": \")\n    )\n    if pprint:\n        for r in results:\n            print(r[:200])\n            print()\n    return results\n\n\nresults = search_reviews(df, \"delicious beans\", n=3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:33:33.608813Z","iopub.execute_input":"2025-04-22T10:33:33.609151Z","iopub.status.idle":"2025-04-22T10:33:34.128571Z","shell.execute_reply.started":"2025-04-22T10:33:33.609123Z","shell.execute_reply":"2025-04-22T10:33:34.127607Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = search_reviews(df, \"whole wheat pasta\", n=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:33:34.129494Z","iopub.execute_input":"2025-04-22T10:33:34.129801Z","iopub.status.idle":"2025-04-22T10:33:34.491862Z","shell.execute_reply.started":"2025-04-22T10:33:34.129778Z","shell.execute_reply":"2025-04-22T10:33:34.490958Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = search_reviews(df, \"bad delivery\", n=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:33:34.492827Z","iopub.execute_input":"2025-04-22T10:33:34.493156Z","iopub.status.idle":"2025-04-22T10:33:34.997391Z","shell.execute_reply.started":"2025-04-22T10:33:34.493131Z","shell.execute_reply":"2025-04-22T10:33:34.996488Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = search_reviews(df, \"spoilt\", n=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:33:53.897812Z","iopub.execute_input":"2025-04-22T10:33:53.898149Z","iopub.status.idle":"2025-04-22T10:33:54.621329Z","shell.execute_reply.started":"2025-04-22T10:33:53.898125Z","shell.execute_reply":"2025-04-22T10:33:54.620359Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = search_reviews(df, \"pet food\", n=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:33:54.622468Z","iopub.execute_input":"2025-04-22T10:33:54.622761Z","iopub.status.idle":"2025-04-22T10:33:55.173576Z","shell.execute_reply.started":"2025-04-22T10:33:54.622729Z","shell.execute_reply":"2025-04-22T10:33:55.172057Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Recommendations using embeddings**","metadata":{}},{"cell_type":"code","source":"import textwrap as tr\nfrom typing import List, Optional\n\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom scipy import spatial\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics import average_precision_score, precision_recall_curve\n\nfrom openai import OpenAI\nimport numpy as np\nimport pandas as pd\n\n\n\ndef get_embedding(text: str, model=\"text-embedding-3-small\", **kwargs) -> List[float]:\n    # replace newlines, which can negatively affect performance.\n    text = text.replace(\"\\n\", \" \")\n\n    response = client.embeddings.create(input=[text], model=model, **kwargs)\n\n    return response.data[0].embedding\n\n\nasync def aget_embedding(\n    text: str, model=\"text-embedding-3-small\", **kwargs\n) -> List[float]:\n    # replace newlines, which can negatively affect performance.\n    text = text.replace(\"\\n\", \" \")\n\n    return (await client.embeddings.create(input=[text], model=model, **kwargs))[\n        \"data\"\n    ][0][\"embedding\"]\n\n\ndef get_embeddings(\n    list_of_text: List[str], model=\"text-embedding-3-small\", **kwargs\n) -> List[List[float]]:\n    assert len(list_of_text) <= 2048, \"The batch size should not be larger than 2048.\"\n\n    # replace newlines, which can negatively affect performance.\n    list_of_text = [text.replace(\"\\n\", \" \") for text in list_of_text]\n\n    data = client.embeddings.create(input=list_of_text, model=model, **kwargs).data\n    return [d.embedding for d in data]\n\n\nasync def aget_embeddings(\n    list_of_text: List[str], model=\"text-embedding-3-small\", **kwargs\n) -> List[List[float]]:\n    assert len(list_of_text) <= 2048, \"The batch size should not be larger than 2048.\"\n\n    # replace newlines, which can negatively affect performance.\n    list_of_text = [text.replace(\"\\n\", \" \") for text in list_of_text]\n\n    data = (\n        await client.embeddings.create(input=list_of_text, model=model, **kwargs)\n    ).data\n    return [d.embedding for d in data]\n\n\ndef cosine_similarity(a, b):\n    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n\n\ndef plot_multiclass_precision_recall(\n    y_score, y_true_untransformed, class_list, classifier_name\n):\n    \"\"\"\n    Precision-Recall plotting for a multiclass problem. It plots average precision-recall, per class precision recall and reference f1 contours.\n\n    Code slightly modified, but heavily based on https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html\n    \"\"\"\n    n_classes = len(class_list)\n    y_true = pd.concat(\n        [(y_true_untransformed == class_list[i]) for i in range(n_classes)], axis=1\n    ).values\n\n    # For each class\n    precision = dict()\n    recall = dict()\n    average_precision = dict()\n    for i in range(n_classes):\n        precision[i], recall[i], _ = precision_recall_curve(y_true[:, i], y_score[:, i])\n        average_precision[i] = average_precision_score(y_true[:, i], y_score[:, i])\n\n    # A \"micro-average\": quantifying score on all classes jointly\n    precision_micro, recall_micro, _ = precision_recall_curve(\n        y_true.ravel(), y_score.ravel()\n    )\n    average_precision_micro = average_precision_score(y_true, y_score, average=\"micro\")\n    print(\n        str(classifier_name)\n        + \" - Average precision score over all classes: {0:0.2f}\".format(\n            average_precision_micro\n        )\n    )\n # setup plot details\n    plt.figure(figsize=(9, 10))\n    f_scores = np.linspace(0.2, 0.8, num=4)\n    lines = []\n    labels = []\n    for f_score in f_scores:\n        x = np.linspace(0.01, 1)\n        y = f_score * x / (2 * x - f_score)\n        (l,) = plt.plot(x[y >= 0], y[y >= 0], color=\"gray\", alpha=0.2)\n        plt.annotate(\"f1={0:0.1f}\".format(f_score), xy=(0.9, y[45] + 0.02))\n\n    lines.append(l)\n    labels.append(\"iso-f1 curves\")\n    (l,) = plt.plot(recall_micro, precision_micro, color=\"gold\", lw=2)\n    lines.append(l)\n    labels.append(\n        \"average Precision-recall (auprc = {0:0.2f})\" \"\".format(average_precision_micro)\n    )\n\n    for i in range(n_classes):\n        (l,) = plt.plot(recall[i], precision[i], lw=2)\n        lines.append(l)\n        labels.append(\n            \"Precision-recall for class `{0}` (auprc = {1:0.2f})\"\n            \"\".format(class_list[i], average_precision[i])\n        )\n\n    fig = plt.gcf()\n    fig.subplots_adjust(bottom=0.25)\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel(\"Recall\")\n    plt.ylabel(\"Precision\")\n    plt.title(f\"{classifier_name}: Precision-Recall curve for each class\")\n    plt.legend(lines, labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T12:07:16.083677Z","iopub.execute_input":"2025-04-22T12:07:16.084002Z","iopub.status.idle":"2025-04-22T12:07:16.101234Z","shell.execute_reply.started":"2025-04-22T12:07:16.083977Z","shell.execute_reply":"2025-04-22T12:07:16.099982Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef distances_from_embeddings(\n    query_embedding: List[float],\n    embeddings: List[List[float]],\n    distance_metric=\"cosine\",\n) -> List[List]:\n    \"\"\"Return the distances between a query embedding and a list of embeddings.\"\"\"\n    distance_metrics = {\n        \"cosine\": spatial.distance.cosine,\n        \"L1\": spatial.distance.cityblock,\n        \"L2\": spatial.distance.euclidean,\n        \"Linf\": spatial.distance.chebyshev,\n    }\n    distances = [\n        distance_metrics[distance_metric](query_embedding, embedding)\n        for embedding in embeddings\n    ]\n    return distances\n\n\ndef indices_of_nearest_neighbors_from_distances(distances) -> np.ndarray:\n    \"\"\"Return a list of indices of nearest neighbors from a list of distances.\"\"\"\n    return np.argsort(distances)\n\n\ndef pca_components_from_embeddings(\n    embeddings: List[List[float]], n_components=2\n) -> np.ndarray:\n    \"\"\"Return the PCA components of a list of embeddings.\"\"\"\n    pca = PCA(n_components=n_components)\n    array_of_embeddings = np.array(embeddings)\n    return pca.fit_transform(array_of_embeddings)\n\n\ndef tsne_components_from_embeddings(\n    embeddings: List[List[float]], n_components=2, **kwargs\n) -> np.ndarray:\n    \"\"\"Returns t-SNE components of a list of embeddings.\"\"\"\n    # use better defaults if not specified\n    if \"init\" not in kwargs.keys():\n        kwargs[\"init\"] = \"pca\"\n    if \"learning_rate\" not in kwargs.keys():\n        kwargs[\"learning_rate\"] = \"auto\"\n    tsne = TSNE(n_components=n_components, **kwargs)\n    array_of_embeddings = np.array(embeddings)\n    return tsne.fit_transform(array_of_embeddings)\n\n\ndef chart_from_components(\n    components: np.ndarray,\n    labels: Optional[List[str]] = None,\n    strings: Optional[List[str]] = None,\n    x_title=\"Component 0\",\n    y_title=\"Component 1\",\n    mark_size=5,\n    **kwargs,\n):\n    \"\"\"Return an interactive 2D chart of embedding components.\"\"\"\n    empty_list = [\"\" for _ in components]\n    data = pd.DataFrame(\n        {\n            x_title: components[:, 0],\n            y_title: components[:, 1],\n            \"label\": labels if labels else empty_list,\n            \"string\": [\"<br>\".join(tr.wrap(string, width=30)) for string in strings]\n            if strings\n            else empty_list,\n        }\n    )\n    chart = px.scatter(\n        data,\n        x=x_title,\n        y=y_title,\n        color=\"label\" if labels else None,\n        symbol=\"label\" if labels else None,\n        hover_data=[\"string\"] if strings else None,\n        **kwargs,\n    ).update_traces(marker=dict(size=mark_size))\n    return chart\n\n\ndef chart_from_components_3D(\n    components: np.ndarray,\n    labels: Optional[List[str]] = None,\n    strings: Optional[List[str]] = None,\n    x_title: str = \"Component 0\",\n    y_title: str = \"Component 1\",\n    z_title: str = \"Compontent 2\",\n    mark_size: int = 5,\n    **kwargs,\n):\n    \"\"\"Return an interactive 3D chart of embedding components.\"\"\"\n    empty_list = [\"\" for _ in components]\n    data = pd.DataFrame(\n        {\n            x_title: components[:, 0],\n            y_title: components[:, 1],\n            z_title: components[:, 2],\n            \"label\": labels if labels else empty_list,\n            \"string\": [\"<br>\".join(tr.wrap(string, width=30)) for string in strings]\n            if strings\n            else empty_list,\n        }\n    )\n    chart = px.scatter_3d(\n        data,\n        x=x_title,\n        y=y_title,\n        z=z_title,\n        color=\"label\" if labels else None,\n        symbol=\"label\" if labels else None,\n        hover_data=[\"string\"] if strings else None,\n        **kwargs,\n    ).update_traces(marker=dict(size=mark_size))\n    return chart","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T12:05:02.665742Z","iopub.execute_input":"2025-04-22T12:05:02.666343Z","iopub.status.idle":"2025-04-22T12:05:02.680853Z","shell.execute_reply.started":"2025-04-22T12:05:02.666314Z","shell.execute_reply":"2025-04-22T12:05:02.679516Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport pickle\n\nEMBEDDING_MODEL = \"text-embedding-3-small\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:46:51.092394Z","iopub.execute_input":"2025-04-22T10:46:51.092724Z","iopub.status.idle":"2025-04-22T10:46:51.097485Z","shell.execute_reply.started":"2025-04-22T10:46:51.092699Z","shell.execute_reply":"2025-04-22T10:46:51.096454Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# load data (full dataset available at http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html)\ndataset_path = \"/kaggle/input/ag-news-samples-csv/AG_news_10_samples.csv\"\ndf = pd.read_csv(dataset_path)\n\nn_examples = 100\ndf.head(n_examples)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:09:15.853420Z","iopub.execute_input":"2025-04-22T11:09:15.853789Z","iopub.status.idle":"2025-04-22T11:09:15.879152Z","shell.execute_reply.started":"2025-04-22T11:09:15.853764Z","shell.execute_reply":"2025-04-22T11:09:15.878099Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print the title, description, and label of each example\nfor idx, row in df.head(n_examples).iterrows():\n    print(\"\")\n    print(f\"Title: {row['title']}\")\n    print(f\"Description: {row['description']}\")\n    print(f\"Label: {row['label']}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:09:19.476660Z","iopub.execute_input":"2025-04-22T11:09:19.477530Z","iopub.status.idle":"2025-04-22T11:09:19.483702Z","shell.execute_reply.started":"2025-04-22T11:09:19.477502Z","shell.execute_reply":"2025-04-22T11:09:19.482728Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# establish a cache of embeddings to avoid recomputing\n# cache is a dict of tuples (text, model) -> embedding, saved as a pickle file\n\n# set path to embedding cache\nembedding_cache_path = \"/kaggle/working/recommendations_embeddings_cache.pkl\"\n\n# load the cache if it exists, and save a copy to disk\ntry:\n    embedding_cache = pd.read_pickle(embedding_cache_path)\nexcept FileNotFoundError:\n    embedding_cache = {}\nwith open(embedding_cache_path, \"wb\") as embedding_cache_file:\n    pickle.dump(embedding_cache, embedding_cache_file)\n\n# define a function to retrieve embeddings from the cache if present, and otherwise request via the API\ndef embedding_from_string(\n    string: str,\n    model: str = EMBEDDING_MODEL,\n    embedding_cache=embedding_cache\n) -> list:\n    \"\"\"Return embedding of given string, using a cache to avoid recomputing.\"\"\"\n    if (string, model) not in embedding_cache.keys():\n        embedding_cache[(string, model)] = get_embedding(string, model)\n        with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n            pickle.dump(embedding_cache, embedding_cache_file)\n    return embedding_cache[(string, model)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:09:23.223273Z","iopub.execute_input":"2025-04-22T11:09:23.223583Z","iopub.status.idle":"2025-04-22T11:09:23.233201Z","shell.execute_reply.started":"2025-04-22T11:09:23.223561Z","shell.execute_reply":"2025-04-22T11:09:23.232152Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def print_recommendations_from_strings(\n    strings: list[str],\n    index_of_source_string: int,\n    k_nearest_neighbors: int = 1,\n    model=EMBEDDING_MODEL,\n) -> list[int]:\n    \"\"\"Print out the k nearest neighbors of a given string.\"\"\"\n    # get embeddings for all strings\n    embeddings = [embedding_from_string(string, model=model) for string in strings]\n\n    # get the embedding of the source string\n    query_embedding = embeddings[index_of_source_string]\n\n    # get distances between the source embedding and other embeddings (function from utils.embeddings_utils.py)\n    distances = distances_from_embeddings(query_embedding, embeddings, distance_metric=\"cosine\")\n    \n    # get indices of nearest neighbors (function from utils.utils.embeddings_utils.py)\n    indices_of_nearest_neighbors = indices_of_nearest_neighbors_from_distances(distances)\n\n    # print out source string\n    query_string = strings[index_of_source_string]\n    print(f\"Source string: {query_string}\")\n    # print out its k nearest neighbors\n    k_counter = 0\n    for i in indices_of_nearest_neighbors:\n        # skip any strings that are identical matches to the starting string\n        if query_string == strings[i]:\n            continue\n        # stop after printing out k articles\n        if k_counter >= k_nearest_neighbors:\n            break\n        k_counter += 1\n\n        # print out the similar strings and their distances\n        print(\n            f\"\"\"\n        --- Recommendation #{k_counter} (nearest neighbor {k_counter} of {k_nearest_neighbors}) ---\n        String: {strings[i]}\n        Distance: {distances[i]:0.3f}\"\"\"\n        )\n\n    return indices_of_nearest_neighbors\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:09:29.310905Z","iopub.execute_input":"2025-04-22T11:09:29.311234Z","iopub.status.idle":"2025-04-22T11:09:29.319173Z","shell.execute_reply.started":"2025-04-22T11:09:29.311210Z","shell.execute_reply":"2025-04-22T11:09:29.317845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"article_descriptions = df[\"description\"].tolist()\n\ntony_blair_articles = print_recommendations_from_strings(\n    strings=article_descriptions,  # let's base similarity off of the article description\n    index_of_source_string=0,  # articles similar to the first one about Tony Blair\n    k_nearest_neighbors=5,  # 5 most similar articles\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:09:33.928405Z","iopub.execute_input":"2025-04-22T11:09:33.929145Z","iopub.status.idle":"2025-04-22T11:09:33.938555Z","shell.execute_reply.started":"2025-04-22T11:09:33.929110Z","shell.execute_reply":"2025-04-22T11:09:33.937710Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chipset_security_articles = print_recommendations_from_strings(\n    strings=article_descriptions,  # let's base similarity off of the article description\n    index_of_source_string=1,  # let's look at articles similar to the second one about a more secure chipset\n    k_nearest_neighbors=5,  # let's look at the 5 most similar articles\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:49:59.384167Z","iopub.execute_input":"2025-04-22T10:49:59.384482Z","iopub.status.idle":"2025-04-22T10:49:59.393002Z","shell.execute_reply.started":"2025-04-22T10:49:59.384458Z","shell.execute_reply":"2025-04-22T10:49:59.392127Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"article_descriptions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:09:40.259785Z","iopub.execute_input":"2025-04-22T11:09:40.260160Z","iopub.status.idle":"2025-04-22T11:09:40.265960Z","shell.execute_reply.started":"2025-04-22T11:09:40.260133Z","shell.execute_reply":"2025-04-22T11:09:40.265085Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# as an example, take the first description from the dataset\nexample_string = df[\"description\"].values[0]\nprint(f\"\\nExample string: {example_string}\")\n\n# print the first 10 dimensions of the embedding\nexample_embedding = embedding_from_string(example_string)\nprint(f\"\\nExample embedding: {example_embedding[:10]}...\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:48:16.193859Z","iopub.execute_input":"2025-04-22T10:48:16.194236Z","iopub.status.idle":"2025-04-22T10:48:16.200162Z","shell.execute_reply.started":"2025-04-22T10:48:16.194209Z","shell.execute_reply":"2025-04-22T10:48:16.199137Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chipset_security_articles = print_recommendations_from_strings(\n    strings=article_descriptions,  # let's base similarity off of the article description\n    index_of_source_string=1,  # let's look at articles similar to the second one about a more secure chipset\n    k_nearest_neighbors=5,  # let's look at the 5 most similar articles\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T10:50:19.569575Z","iopub.execute_input":"2025-04-22T10:50:19.569907Z","iopub.status.idle":"2025-04-22T10:50:19.577918Z","shell.execute_reply.started":"2025-04-22T10:50:19.569883Z","shell.execute_reply":"2025-04-22T10:50:19.576879Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n**Appendix: Using embeddings in more sophisticated recommendersA more sophisticated way to build a recommender system is to train a machine learning model that takes in tens or hundreds of signals, such as item popularity or user click data. Even in this system, embeddings can be a very useful signal into the recommender, especially for items that are being 'cold started' with no user data yet (e.g., a brand new product added to the catalog without any clicks yet).**\n","metadata":{}},{"cell_type":"markdown","source":"\n**Appendix: Using embeddings to visualize similar articlesTo get a sense of what our nearest neighbor recommender is doing, let's visualize the article embeddings. Although we can't plot the 2048 dimensions of each embedding vector, we can use techniques like t-SNE or PCA to compress the embeddings down into 2 or 3 dimensions, which we can chart.**\n","metadata":{}},{"cell_type":"code","source":"# get embeddings for all article descriptions\nembeddings = [embedding_from_string(string) for string in article_descriptions]\n# compress the 2048-dimensional embeddings into 2 dimensions using t-SNE\ntsne_components = tsne_components_from_embeddings(embeddings, perplexity=3)\n# get the article labels for coloring the chart\nlabels = df[\"label\"].tolist()\n\nchart_from_components(\n    components=tsne_components,\n    labels=labels,\n    strings=article_descriptions,\n    width=600,\n    height=500,\n    title=\"t-SNE components of article descriptions\",\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:32:52.454718Z","iopub.execute_input":"2025-04-22T11:32:52.455066Z","iopub.status.idle":"2025-04-22T11:32:52.785917Z","shell.execute_reply.started":"2025-04-22T11:32:52.455042Z","shell.execute_reply":"2025-04-22T11:32:52.784948Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create labels for the recommended articles\ndef nearest_neighbor_labels(\n    list_of_indices: list[int],\n    k_nearest_neighbors: int = 5\n) -> list[str]:\n    \"\"\"Return a list of labels to color the k nearest neighbors.\"\"\"\n    labels = [\"Other\" for _ in list_of_indices]\n    source_index = list_of_indices[0]\n    labels[source_index] = \"Source\"\n    for i in range(k_nearest_neighbors):\n        nearest_neighbor_index = list_of_indices[i + 1]\n        labels[nearest_neighbor_index] = f\"Nearest neighbor (top {k_nearest_neighbors})\"\n    return labels\n\n\ntony_blair_labels = nearest_neighbor_labels(tony_blair_articles, k_nearest_neighbors=5)\nchipset_security_labels = nearest_neighbor_labels(chipset_security_articles, k_nearest_neighbors=5\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:33:45.147473Z","iopub.execute_input":"2025-04-22T11:33:45.147808Z","iopub.status.idle":"2025-04-22T11:33:45.154123Z","shell.execute_reply.started":"2025-04-22T11:33:45.147787Z","shell.execute_reply":"2025-04-22T11:33:45.152822Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# a 2D chart of nearest neighbors of the Tony Blair article\nchart_from_components(\n    components=tsne_components,\n    labels=tony_blair_labels,\n    strings=article_descriptions,\n    width=600,\n    height=500,\n    title=\"Nearest neighbors of the Tony Blair article\",\n    category_orders={\"label\": [\"Other\", \"Nearest neighbor (top 5)\", \"Source\"]},\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:30:21.591553Z","iopub.execute_input":"2025-04-22T11:30:21.591887Z","iopub.status.idle":"2025-04-22T11:30:21.658173Z","shell.execute_reply.started":"2025-04-22T11:30:21.591862Z","shell.execute_reply":"2025-04-22T11:30:21.657294Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# a 2D chart of nearest neighbors of the chipset security article\nchart_from_components(\n    components=tsne_components,\n    labels=chipset_security_labels,\n    strings=article_descriptions,\n    width=600,\n    height=500,\n    title=\"Nearest neighbors of the chipset security article\",\n    category_orders={\"label\": [\"Other\", \"Nearest neighbor (top 5)\", \"Source\"]},\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:34:08.060099Z","iopub.execute_input":"2025-04-22T11:34:08.060441Z","iopub.status.idle":"2025-04-22T11:34:08.126025Z","shell.execute_reply.started":"2025-04-22T11:34:08.060416Z","shell.execute_reply":"2025-04-22T11:34:08.125147Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Visualizing the embeddings in 2D**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.manifold import TSNE\nimport numpy as np\nfrom ast import literal_eval\n\n# Load the embeddings\ndatafile_path = \"/kaggle/working/fine_food_reviews_with_embeddings_1k.csv\"\ndf = pd.read_csv(datafile_path)\n\n# Convert to a list of lists of floats\nmatrix = np.array(df.embedding.apply(literal_eval).to_list())\n\n# Create a t-SNE model and transform the data\ntsne = TSNE(n_components=2, perplexity=15, random_state=42, init='random', learning_rate=200)\nvis_dims = tsne.fit_transform(matrix)\nvis_dims.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:38:58.338373Z","iopub.execute_input":"2025-04-22T11:38:58.338766Z","iopub.status.idle":"2025-04-22T11:39:09.991455Z","shell.execute_reply.started":"2025-04-22T11:38:58.338739Z","shell.execute_reply":"2025-04-22T11:39:09.990212Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib\nimport numpy as np\n\ncolors = [\"red\", \"darkorange\", \"gold\", \"turquoise\", \"darkgreen\"]\nx = [x for x,y in vis_dims]\ny = [y for x,y in vis_dims]\ncolor_indices = df.Score.values - 1\n\ncolormap = matplotlib.colors.ListedColormap(colors)\nplt.scatter(x, y, c=color_indices, cmap=colormap, alpha=0.3)\nfor score in [0,1,2,3,4]:\n    avg_x = np.array(x)[df.Score-1==score].mean()\n    avg_y = np.array(y)[df.Score-1==score].mean()\n    color = colors[score]\n    plt.scatter(avg_x, avg_y, marker='x', color=color, s=100)\n\nplt.title(\"Amazon ratings visualized in language using t-SNE\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:40:31.134432Z","iopub.execute_input":"2025-04-22T11:40:31.135108Z","iopub.status.idle":"2025-04-22T11:40:31.513947Z","shell.execute_reply.started":"2025-04-22T11:40:31.135062Z","shell.execute_reply":"2025-04-22T11:40:31.513047Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Regression using the embeddings**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom ast import literal_eval\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\ndatafile_path = \"/kaggle/working/fine_food_reviews_with_embeddings_1k.csv\"\n\ndf = pd.read_csv(datafile_path)\ndf[\"embedding\"] = df.embedding.apply(literal_eval).apply(np.array)\n\nX_train, X_test, y_train, y_test = train_test_split(list(df.embedding.values), df.Score, test_size=0.2, random_state=42)\n\nrfr = RandomForestRegressor(n_estimators=100)\nrfr.fit(X_train, y_train)\npreds = rfr.predict(X_test)\n\nmse = mean_squared_error(y_test, preds)\nmae = mean_absolute_error(y_test, preds)\n\nprint(f\"text-embedding-3-small performance on 1k Amazon reviews: mse={mse:.2f}, mae={mae:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:56:56.349064Z","iopub.execute_input":"2025-04-22T11:56:56.349386Z","iopub.status.idle":"2025-04-22T11:58:33.228361Z","shell.execute_reply.started":"2025-04-22T11:56:56.349364Z","shell.execute_reply":"2025-04-22T11:58:33.227518Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bmse = mean_squared_error(y_test, np.repeat(y_test.mean(), len(y_test)))\nbmae = mean_absolute_error(y_test, np.repeat(y_test.mean(), len(y_test)))\nprint(\n    f\"Dummy mean prediction performance on Amazon reviews: mse={bmse:.2f}, mae={bmae:.2f}\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:58:33.229964Z","iopub.execute_input":"2025-04-22T11:58:33.230317Z","iopub.status.idle":"2025-04-22T11:58:33.237430Z","shell.execute_reply.started":"2025-04-22T11:58:33.230294Z","shell.execute_reply":"2025-04-22T11:58:33.236691Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Classification using embeddings**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom ast import literal_eval\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\n\ndatafile_path = \"/kaggle/working/fine_food_reviews_with_embeddings_1k.csv\"\n\ndf = pd.read_csv(datafile_path)\ndf[\"embedding\"] = df.embedding.apply(literal_eval).apply(np.array)  # convert string to array\n\n# split data into train and test\nX_train, X_test, y_train, y_test = train_test_split(\n    list(df.embedding.values), df.Score, test_size=0.2, random_state=42\n)\n\n# train random forest classifier\nclf = RandomForestClassifier(n_estimators=100)\nclf.fit(X_train, y_train)\npreds = clf.predict(X_test)\nprobas = clf.predict_proba(X_test)\n\nreport = classification_report(y_test, preds)\nprint(report)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T12:02:23.060556Z","iopub.execute_input":"2025-04-22T12:02:23.060883Z","iopub.status.idle":"2025-04-22T12:02:32.626916Z","shell.execute_reply.started":"2025-04-22T12:02:23.060860Z","shell.execute_reply":"2025-04-22T12:02:32.625970Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_multiclass_precision_recall(probas, y_test, [1, 2, 3, 4, 5], clf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T12:07:37.133035Z","iopub.execute_input":"2025-04-22T12:07:37.133930Z","iopub.status.idle":"2025-04-22T12:07:37.686144Z","shell.execute_reply.started":"2025-04-22T12:07:37.133894Z","shell.execute_reply":"2025-04-22T12:07:37.685226Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Zero-shot classification with embeddings**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom ast import literal_eval\n\nfrom sklearn.metrics import classification_report\n\nEMBEDDING_MODEL = \"text-embedding-3-small\"\n\ndatafile_path = \"/kaggle/working/fine_food_reviews_with_embeddings_1k.csv\"\n\ndf = pd.read_csv(datafile_path)\ndf[\"embedding\"] = df.embedding.apply(literal_eval).apply(np.array)\n\n# convert 5-star rating to binary sentiment\ndf = df[df.Score != 3]\ndf[\"sentiment\"] = df.Score.replace({1: \"negative\", 2: \"negative\", 4: \"positive\", 5: \"positive\"})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T12:23:42.161652Z","iopub.execute_input":"2025-04-22T12:23:42.161977Z","iopub.status.idle":"2025-04-22T12:23:49.267023Z","shell.execute_reply.started":"2025-04-22T12:23:42.161953Z","shell.execute_reply":"2025-04-22T12:23:49.266243Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import PrecisionRecallDisplay\n\ndef evaluate_embeddings_approach(\n    labels = ['negative', 'positive'],\n    model = EMBEDDING_MODEL,\n):\n    label_embeddings = [get_embedding(label, model=model) for label in labels]\n\n    def label_score(review_embedding, label_embeddings):\n        return cosine_similarity(review_embedding, label_embeddings[1]) - cosine_similarity(review_embedding, label_embeddings[0])\n\n    probas = df[\"embedding\"].apply(lambda x: label_score(x, label_embeddings))\n    preds = probas.apply(lambda x: 'positive' if x>0 else 'negative')\n\n    report = classification_report(df.sentiment, preds)\n    print(report)\n\n    display = PrecisionRecallDisplay.from_predictions(df.sentiment, probas, pos_label='positive')\n    _ = display.ax_.set_title(\"2-class Precision-Recall curve\")\n\nevaluate_embeddings_approach(labels=['negative', 'positive'], model=EMBEDDING_MODEL)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T12:24:32.099742Z","iopub.execute_input":"2025-04-22T12:24:32.100040Z","iopub.status.idle":"2025-04-22T12:24:32.141765Z","shell.execute_reply.started":"2025-04-22T12:24:32.100015Z","shell.execute_reply":"2025-04-22T12:24:32.140702Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**User and product embeddings**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom ast import literal_eval\n\ndf = pd.read_csv('/kaggle/working/fine_food_reviews_with_embeddings_1k.csv', index_col=0)  # note that you will need to generate this file to run the code below\ndf.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T12:37:19.556714Z","iopub.execute_input":"2025-04-22T12:37:19.557036Z","iopub.status.idle":"2025-04-22T12:37:19.904749Z","shell.execute_reply.started":"2025-04-22T12:37:19.557012Z","shell.execute_reply":"2025-04-22T12:37:19.903848Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['babbage_similarity'] = df[\"embedding\"].apply(literal_eval).apply(np.array)\nX_train, X_test, y_train, y_test = train_test_split(df, df.Score, test_size = 0.2, random_state=42)\n\nuser_embeddings = X_train.groupby('UserId').babbage_similarity.apply(np.mean)\nprod_embeddings = X_train.groupby('ProductId').babbage_similarity.apply(np.mean)\nlen(user_embeddings), len(prod_embeddings)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T12:37:31.389254Z","iopub.execute_input":"2025-04-22T12:37:31.389623Z","iopub.status.idle":"2025-04-22T12:37:38.353072Z","shell.execute_reply.started":"2025-04-22T12:37:31.389596Z","shell.execute_reply":"2025-04-22T12:37:38.352311Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# evaluate embeddings as recommendations on X_test\ndef evaluate_single_match(row):\n    user_id = row.UserId\n    product_id = row.ProductId\n    try:\n        user_embedding = user_embeddings[user_id]\n        product_embedding = prod_embeddings[product_id]\n        similarity = cosine_similarity(user_embedding, product_embedding)\n        return similarity\n    except Exception as e:\n        return np.nan\n\nX_test['cosine_similarity'] = X_test.apply(evaluate_single_match, axis=1)\nX_test['percentile_cosine_similarity'] = X_test.cosine_similarity.rank(pct=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T12:37:56.325927Z","iopub.execute_input":"2025-04-22T12:37:56.326234Z","iopub.status.idle":"2025-04-22T12:37:56.347850Z","shell.execute_reply.started":"2025-04-22T12:37:56.326211Z","shell.execute_reply":"2025-04-22T12:37:56.346968Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport statsmodels.api as sm\n\n\ncorrelation = X_test[['percentile_cosine_similarity', 'Score']].corr().values[0,1]\nprint('Correlation between user & vector similarity percentile metric and review number of stars (score): %.2f%%' % (100*correlation))\n\n# boxplot of cosine similarity for each score\nX_test.boxplot(column='percentile_cosine_similarity', by='Score')\nplt.title('')\nplt.show()\nplt.close()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T12:38:11.241274Z","iopub.execute_input":"2025-04-22T12:38:11.241628Z","iopub.status.idle":"2025-04-22T12:38:13.682326Z","shell.execute_reply.started":"2025-04-22T12:38:11.241603Z","shell.execute_reply":"2025-04-22T12:38:13.680983Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Clustering**","metadata":{}},{"cell_type":"code","source":"# imports\nimport numpy as np\nimport pandas as pd\nfrom ast import literal_eval\n\n# load data\ndatafile_path = \"/kaggle/working/fine_food_reviews_with_embeddings_1k.csv\"\n\ndf = pd.read_csv(datafile_path)\ndf[\"embedding\"] = df.embedding.apply(literal_eval).apply(np.array)  # convert string to numpy array\nmatrix = np.vstack(df.embedding.values)\nmatrix.shape\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T12:58:18.663834Z","iopub.execute_input":"2025-04-22T12:58:18.664141Z","iopub.status.idle":"2025-04-22T12:58:25.728392Z","shell.execute_reply.started":"2025-04-22T12:58:18.664116Z","shell.execute_reply":"2025-04-22T12:58:25.727692Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.cluster import KMeans\n\nn_clusters = 4\n\nkmeans = KMeans(n_clusters=n_clusters, init=\"k-means++\", random_state=42)\nkmeans.fit(matrix)\nlabels = kmeans.labels_\ndf[\"Cluster\"] = labels\n\ndf.groupby(\"Cluster\").Score.mean().sort_values()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T12:58:25.729900Z","iopub.execute_input":"2025-04-22T12:58:25.730230Z","iopub.status.idle":"2025-04-22T12:58:26.375291Z","shell.execute_reply.started":"2025-04-22T12:58:25.730201Z","shell.execute_reply":"2025-04-22T12:58:26.373856Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.manifold import TSNE\nimport matplotlib\nimport matplotlib.pyplot as plt\n\ntsne = TSNE(n_components=2, perplexity=15, random_state=42, init=\"random\", learning_rate=200)\nvis_dims2 = tsne.fit_transform(matrix)\n\nx = [x for x, y in vis_dims2]\ny = [y for x, y in vis_dims2]\n\nfor category, color in enumerate([\"purple\", \"green\", \"red\", \"blue\"]):\n    xs = np.array(x)[df.Cluster == category]\n    ys = np.array(y)[df.Cluster == category]\n    plt.scatter(xs, ys, color=color, alpha=0.3)\n\n    avg_x = xs.mean()\n    avg_y = ys.mean()\n\n    plt.scatter(avg_x, avg_y, marker=\"x\", color=color, s=100)\nplt.title(\"Clusters identified visualized in language 2d using t-SNE\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T12:58:26.375870Z","iopub.execute_input":"2025-04-22T12:58:26.376084Z","iopub.status.idle":"2025-04-22T12:58:30.792001Z","shell.execute_reply.started":"2025-04-22T12:58:26.376066Z","shell.execute_reply":"2025-04-22T12:58:30.791067Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from openai import OpenAI\nimport os\n\nclient = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"<your OpenAI API key if not set as env var>\"))\n\n# Reading a review which belong to each group.\nrev_per_cluster = 5\n\nfor i in range(n_clusters):\n    print(f\"Cluster {i} Theme:\", end=\" \")\n\n    reviews = \"\\n\".join(\n        df[df.Cluster == i]\n        .combined.str.replace(\"Title: \", \"\")\n        .str.replace(\"\\n\\nContent: \", \":  \")\n        .sample(rev_per_cluster, random_state=42)\n        .values\n    )\n\n    messages = [\n        {\"role\": \"user\", \"content\": f'What do the following customer reviews have in common?\\n\\nCustomer reviews:\\n\"\"\"\\n{reviews}\\n\"\"\"\\n\\nTheme:'}\n    ]\n\n    response = client.chat.completions.create(\n        model=\"gpt-4\",\n        messages=messages,\n        temperature=0,\n        max_tokens=64,\n        top_p=1,\n        frequency_penalty=0,\n        presence_penalty=0)\n    print(response.choices[0].message.content.replace(\"\\n\", \"\"))\n\n    sample_cluster_rows = df[df.Cluster == i].sample(rev_per_cluster, random_state=42)\n    for j in range(rev_per_cluster):\n        print(sample_cluster_rows.Score.values[j], end=\", \")\n        print(sample_cluster_rows.Summary.values[j], end=\":   \")\n        print(sample_cluster_rows.Text.str[:70].values[j])\n\n    print(\"-\" * 100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T12:58:35.743069Z","iopub.execute_input":"2025-04-22T12:58:35.743376Z","iopub.status.idle":"2025-04-22T12:58:40.385617Z","shell.execute_reply.started":"2025-04-22T12:58:35.743345Z","shell.execute_reply":"2025-04-22T12:58:40.384640Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}