{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-29T18:58:19.322632Z","iopub.execute_input":"2025-09-29T18:58:19.322967Z","iopub.status.idle":"2025-09-29T18:58:19.852812Z","shell.execute_reply.started":"2025-09-29T18:58:19.322933Z","shell.execute_reply":"2025-09-29T18:58:19.851344Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\nos.environ[\"GOOGLE_API_KEY\"] = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\nos.environ[\"GOOGLE_CSE_ID\"] = UserSecretsClient().get_secret(\"GOOGLE_CSE_ID\")\nos.environ[\"OPENAI_API_KEY\"] = UserSecretsClient().get_secret(\"OPENAI_API_KEY\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T02:36:13.203299Z","iopub.execute_input":"2025-09-30T02:36:13.203624Z","iopub.status.idle":"2025-09-30T02:36:13.631415Z","shell.execute_reply.started":"2025-09-30T02:36:13.203601Z","shell.execute_reply":"2025-09-30T02:36:13.630560Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q langchain-openai langchain-community langchain-core requests duckduckgo-search","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T02:09:55.714272Z","iopub.execute_input":"2025-09-30T02:09:55.715102Z","iopub.status.idle":"2025-09-30T02:09:59.791144Z","shell.execute_reply.started":"2025-09-30T02:09:55.715071Z","shell.execute_reply":"2025-09-30T02:09:59.789841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain_openai import ChatOpenAI\nfrom langchain_core.tools import tool\nimport requests","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T02:10:06.953377Z","iopub.execute_input":"2025-09-30T02:10:06.953708Z","iopub.status.idle":"2025-09-30T02:10:06.957997Z","shell.execute_reply.started":"2025-09-30T02:10:06.953686Z","shell.execute_reply":"2025-09-30T02:10:06.957006Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%pip install --upgrade --quiet  langchain-google-community","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T02:10:10.323107Z","iopub.execute_input":"2025-09-30T02:10:10.323559Z","iopub.status.idle":"2025-09-30T02:10:14.669549Z","shell.execute_reply.started":"2025-09-30T02:10:10.323521Z","shell.execute_reply":"2025-09-30T02:10:14.668550Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain_core.tools import Tool\nfrom langchain_google_community import GoogleSearchAPIWrapper\n\nsearch = GoogleSearchAPIWrapper()\n\ntool = Tool(\n    name=\"google_search\",\n    description=\"Search Google for recent results.\",\n    func=search.run,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T02:33:55.748290Z","iopub.execute_input":"2025-09-30T02:33:55.748579Z","iopub.status.idle":"2025-09-30T02:33:55.756251Z","shell.execute_reply.started":"2025-09-30T02:33:55.748561Z","shell.execute_reply":"2025-09-30T02:33:55.755474Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tool.run(\"Obama's first name?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T02:34:00.331766Z","iopub.execute_input":"2025-09-30T02:34:00.332204Z","iopub.status.idle":"2025-09-30T02:34:00.804855Z","shell.execute_reply.started":"2025-09-30T02:34:00.332170Z","shell.execute_reply":"2025-09-30T02:34:00.803768Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport requests\nfrom langchain_core.tools import tool as lc_tool   # avoid name clash\nfrom langchain_core.tools import Tool\n\n@lc_tool\ndef get_weather_data(city: str) -> str:\n    \"\"\"Fetch current weather for a given city from Weatherstack\"\"\"\n    access_key = os.getenv(\"WEATHERSTACK_API_KEY\",\" 2ba1a6e454385464848763c929c5efe2\")  # or paste your key for testing\n    url = f\"http://api.weatherstack.com/current?access_key={access_key}&query={city}\"\n    r = requests.get(url, timeout=20)\n    r.raise_for_status()\n    data = r.json()\n    if \"error\" in data:\n        raise ValueError(data[\"error\"].get(\"info\", \"Weather API error\"))\n\n    loc = data[\"location\"][\"name\"]\n    cur = data[\"current\"]\n    desc = cur[\"weather_descriptions\"][0] if cur.get(\"weather_descriptions\") else \"N/A\"\n    return f\"{loc}: {cur['temperature']}Â°C, {desc}\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T03:03:33.204694Z","iopub.execute_input":"2025-09-30T03:03:33.205313Z","iopub.status.idle":"2025-09-30T03:03:33.215297Z","shell.execute_reply.started":"2025-09-30T03:03:33.205285Z","shell.execute_reply":"2025-09-30T03:03:33.214425Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"get_weather_data.run(\"Delhi\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T03:03:36.383337Z","iopub.execute_input":"2025-09-30T03:03:36.383680Z","iopub.status.idle":"2025-09-30T03:03:36.606365Z","shell.execute_reply.started":"2025-09-30T03:03:36.383620Z","shell.execute_reply":"2025-09-30T03:03:36.605221Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain_openai import ChatOpenAI\nllm = ChatOpenAI()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T02:49:03.682728Z","iopub.execute_input":"2025-09-30T02:49:03.683045Z","iopub.status.idle":"2025-09-30T02:49:03.687888Z","shell.execute_reply.started":"2025-09-30T02:49:03.683024Z","shell.execute_reply":"2025-09-30T02:49:03.686891Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain.agents import create_react_agent, AgentExecutor\nfrom langchain import hub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T02:49:05.995608Z","iopub.execute_input":"2025-09-30T02:49:05.995900Z","iopub.status.idle":"2025-09-30T02:49:06.000105Z","shell.execute_reply.started":"2025-09-30T02:49:05.995881Z","shell.execute_reply":"2025-09-30T02:49:05.999082Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 2: Pull the ReAct prompt from LangChain Hub\nprompt = hub.pull(\"hwchase17/react\")  # pulls the standard ReAct agent prompt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T02:49:12.484919Z","iopub.execute_input":"2025-09-30T02:49:12.485230Z","iopub.status.idle":"2025-09-30T02:49:12.704819Z","shell.execute_reply.started":"2025-09-30T02:49:12.485209Z","shell.execute_reply":"2025-09-30T02:49:12.703687Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 3: Create the ReAct agent manually with the pulled prompt\nagent = create_react_agent(\n    llm=llm,\n    tools=[tool, get_weather_data],\n    prompt=prompt\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T02:49:15.010984Z","iopub.execute_input":"2025-09-30T02:49:15.011550Z","iopub.status.idle":"2025-09-30T02:49:15.016850Z","shell.execute_reply.started":"2025-09-30T02:49:15.011525Z","shell.execute_reply":"2025-09-30T02:49:15.015705Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 4: Wrap it with AgentExecutor\nagent_executor = AgentExecutor(\n    agent=agent,\n    tools=[tool, get_weather_data],\n    verbose=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T02:49:17.175102Z","iopub.execute_input":"2025-09-30T02:49:17.175678Z","iopub.status.idle":"2025-09-30T02:49:17.180471Z","shell.execute_reply.started":"2025-09-30T02:49:17.175652Z","shell.execute_reply":"2025-09-30T02:49:17.179452Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 5: Invoke\nresponse = agent_executor.invoke({\"input\": \"Find the capital of Madhya Pradesh, then find it's current weather condition\"})\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T02:49:19.616174Z","iopub.execute_input":"2025-09-30T02:49:19.616462Z","iopub.status.idle":"2025-09-30T02:49:22.814092Z","shell.execute_reply.started":"2025-09-30T02:49:19.616442Z","shell.execute_reply":"2025-09-30T02:49:22.812812Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"response['output']","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}